{
    "columns":[
        "abstract",
        "title",
        "author",
        "pub_year",
        "author_pub_id",
        "num_citations",
        "pub_url",
        "cites_id",
        "citedby_url",
        "cites_per_year"
    ],
    "index":[
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "data":[
        [
            "We introduce fast algorithms for selecting a random sample of n records without replacement from a pool of N records, where the value of N is unknown beforehand. The main result of the paper is the design and analysis of Algorithm Z; it does the sampling in one pass using constant space and in O(n(1 + log(N\/n))) expected time, which is optimum, up to a constant factor. Several optimizations are studied that collectively improve the speed of the naive version of the algorithm by an order of magnitude. We give an efficient Pascal-like implementation that incorporates these modifications and that is suitable for general use. Theoretical and empirical results indicate that Algorithm Z outperforms current methods by a significant margin.",
            "Random sampling with a reservoir",
            "Jeffrey S Vitter",
            "1985",
            "IeXW2bkAAAAJ:d1gkVwhDpl0C",
            1568,
            "https:\/\/dl.acm.org\/doi\/abs\/10.1145\/3147.3165",
            "12477259931641459543",
            "\/scholar?cites=12477259931641459543",
            {
                "1996":6,
                "1997":3,
                "1998":8,
                "1999":14,
                "2000":18,
                "2001":11,
                "2002":20,
                "2003":26,
                "2004":27,
                "2005":47,
                "2006":65,
                "2007":79,
                "2008":47,
                "2009":61,
                "2010":63,
                "2011":61,
                "2012":66,
                "2013":74,
                "2014":92,
                "2015":88,
                "2016":104,
                "2017":123,
                "2018":141,
                "2019":141,
                "2020":137,
                "2021":9
            }
        ],
        [
            "We provide tight upper and lower bounds, up to a constant factor, for the number of inputs and outputs (I\/OS) between internal memory and secondary storage required for five sorting-related problems: sorting, the fast Fourier transform (FFT), permutation networks, permuting, and matrix transposition. The bounds hold both in the worst case and in the average case, and in several situations the constant factors match. Secondary storage is modeled as a magnetic disk capable of transferring P blocks each containing B records in a single time unit; the records in each block must be input from or output to B contiguous locations on the disk. We give two optimal algorithms for the problems, which are variants of merge sorting and distribution sorting. In particular we show for P = 1 that the standard merge sorting algorithm is an optimal external sorting method, up to a constant factor in the number of I\/Os. Our sorting \u2026",
            "The input\/output complexity of sorting and related problems",
            "Alok Aggarwal and Jeffrey and S Vitter",
            "1988",
            "IeXW2bkAAAAJ:u5HHmVD_uO8C",
            1552,
            "https:\/\/dl.acm.org\/doi\/abs\/10.1145\/48529.48535",
            "3567132514521198468",
            "\/scholar?cites=3567132514521198468",
            {
                "1990":8,
                "1991":6,
                "1992":9,
                "1993":22,
                "1994":16,
                "1995":14,
                "1996":23,
                "1997":26,
                "1998":28,
                "1999":36,
                "2000":36,
                "2001":33,
                "2002":44,
                "2003":43,
                "2004":51,
                "2005":55,
                "2006":63,
                "2007":63,
                "2008":59,
                "2009":61,
                "2010":81,
                "2011":80,
                "2012":90,
                "2013":82,
                "2014":91,
                "2015":75,
                "2016":71,
                "2017":58,
                "2018":76,
                "2019":61,
                "2020":53,
                "2021":6
            }
        ],
        [
            "Data sets in large applications are often too massive to fit completely inside the computers internal memory. The resulting input\/output communication (or I\/O) between fast internal memory and slower external memory (such as disks) can be a major performance bottleneck. In this article we survey the state of the art in the design and analysis of external memory (or EM) algorithms and data structures, where the goal is to exploit locality in order to reduce the I\/O costs. We consider a variety of EM paradigms for solving batched and online problems efficiently in external memory. For the batched problem of sorting and related problems such as permuting and fast Fourier transform, the key paradigms include distribution and merging. The paradigm of disk striping offers an elegant way to use multiple disks in parallel. For sorting, however,  disk striping can be nonoptimal with respect to I\/O, so to gain further improvements \u2026",
            "External memory algorithms and data structures: dealing with massive data",
            "Jeffrey Scott Vitter",
            "2001",
            "IeXW2bkAAAAJ:u-x6o8ySG0sC",
            896,
            "https:\/\/dl.acm.org\/doi\/abs\/10.1145\/384192.384193",
            "16336786270174586246",
            "\/scholar?cites=16336786270174586246",
            {
                "2000":13,
                "2001":32,
                "2002":41,
                "2003":47,
                "2004":53,
                "2005":64,
                "2006":67,
                "2007":73,
                "2008":71,
                "2009":61,
                "2010":47,
                "2011":48,
                "2012":35,
                "2013":32,
                "2014":34,
                "2015":31,
                "2016":27,
                "2017":23,
                "2018":22,
                "2019":22,
                "2020":18,
                "2021":4
            }
        ],
        [
            "We present a novel implementation of compressed su~x arrays exhibiting new tradeoffs between search time and space occupancy for a given text (or sequence) of n symbols over an alphabet E, where each symbol is encoded by lg ]E I bits. We show that compressed su1~x arrays use just nHh + O(n lglg n~ lgl~ I n) bits, while retaining full text indexing functionalities, such as searching any pattern sequence of length m in O(mlg [E[ + polylog(n)) time. The term Hh < lg IEI denotes the hth-order empirical entropy of the text, which means that our index is nearly optimal in space apart from lower-order terms, achieving asymptotically the empirical entropy of the text (with a multiplicative constant 1). If the text is highly compressible so that H~ = o(1) and the alphabet size is small, we obtain a text index with o(m) search time that requires only o(n) bits. Further results and tradeoffs are reported in the paper.",
            "High-order entropy-compressed text indexes",
            "Roberto Grossi and Ankur Gupta and Jeffrey Scott Vitter",
            "2003",
            "IeXW2bkAAAAJ:IjCSPb-OGe4C",
            840,
            "https:\/\/kuscholarworks.ku.edu\/handle\/1808\/7192",
            "6946481020063769737",
            "\/scholar?cites=6946481020063769737",
            {
                "2003":6,
                "2004":14,
                "2005":19,
                "2006":23,
                "2007":42,
                "2008":34,
                "2009":42,
                "2010":46,
                "2011":57,
                "2012":67,
                "2013":70,
                "2014":69,
                "2015":59,
                "2016":56,
                "2017":73,
                "2018":55,
                "2019":39,
                "2020":46,
                "2021":13
            }
        ],
        [
            "The proliferation of online text, such as found on the World Wide Web and in online databases, motivates the need for space-efficient text indexing methods that support fast string searching. We model this scenario as follows: Consider a text T consisting of n symbols drawn from a fixed alphabet . The text T can be represented in  bits by encoding each symbol with  bits. The goal is to support fast online queries for searching any string pattern P of m symbols, with T being fully scanned only once, namely, when the index is created at preprocessing time. The text indexing schemes published in the literature are greedy in terms of space usage: they require  additional bits of space in the worst case. For example, in the standard unit cost RAM, suffix trees and suffix arrays need  memory words, each of  bits. These indexes are larger than the text itself by a multiplicative factor of , which is significant when  is of constant size, such as \u2026",
            "Compressed suffix arrays and suffix trees with applications to text indexing and string matching",
            "Roberto Grossi and Jeffrey Scott Vitter",
            "2005",
            "IeXW2bkAAAAJ:Tyk-4Ss8FVUC",
            769,
            "https:\/\/epubs.siam.org\/doi\/abs\/10.1137\/S0097539702402354",
            "3549339272201641035",
            "\/scholar?cites=3549339272201641035",
            {
                "2004":29,
                "2005":46,
                "2006":37,
                "2007":58,
                "2008":39,
                "2009":61,
                "2010":42,
                "2011":38,
                "2012":43,
                "2013":41,
                "2014":45,
                "2015":45,
                "2016":38,
                "2017":37,
                "2018":32,
                "2019":20,
                "2020":34,
                "2021":8
            }
        ],
        [
            "Query optimization is an integral part of relational database management systems. One important task in query optimization is selectivity estimation, that is, given a query P, we need to estimate the fraction of records in the database that satisfy P. Many commercial database systems maintain histograms to approximate the frequency distribution of values in the attributes of relations.",
            "Wavelet-based histograms for selectivity estimation",
            "Yossi Matias and Jeffrey Scott Vitter and Min Wang",
            "1998",
            "IeXW2bkAAAAJ:2osOgNQ5qMEC",
            565,
            "https:\/\/dl.acm.org\/doi\/abs\/10.1145\/276304.276344",
            "14511886951442420619",
            "\/scholar?cites=14511886951442420619",
            {
                "1998":6,
                "1999":14,
                "2000":9,
                "2001":30,
                "2002":23,
                "2003":33,
                "2004":43,
                "2005":50,
                "2006":48,
                "2007":55,
                "2008":35,
                "2009":48,
                "2010":22,
                "2011":24,
                "2012":16,
                "2013":18,
                "2014":10,
                "2015":9,
                "2016":10,
                "2017":9,
                "2018":10,
                "2019":13,
                "2020":16,
                "2021":1
            }
        ],
        [
            "A new one-pass algorithm for constructing dynamic Huffman codes is introduced and analyzed. We also analyze the one-pass algorithm due to Faller, Gallager, and Knuth. In each algorithm, both the sender and the receiver maintain equivalent dynamically varying Huffman trees, and the coding is done in real time. We show that the number of bits used by the new algorithm to encode a message containing t letters is < t bits more than that used by the conventional two-pass Huffman scheme, independent of the alphabet size. This is best possible in the worst case, for any one-pass Huffman method. Tight upper and lower bounds are derived. Empirical tests show that the encodings produced by the new algorithm are shorter than those of the other one-pass algorithm and, except for long messages, are shorter than those of the two-pass method. The new algorithm is well suited for on-line encoding\/decoding in data \u2026",
            "Design and analysis of dynamic Huffman codes",
            "Jeffrey Scott Vitter",
            "1987",
            "IeXW2bkAAAAJ:zYLM7Y9cAGgC",
            527,
            "https:\/\/dl.acm.org\/doi\/abs\/10.1145\/31846.42227",
            "16239278578122584990",
            "\/scholar?cites=16239278578122584990",
            {
                "1987":6,
                "1988":4,
                "1989":6,
                "1990":5,
                "1991":9,
                "1992":14,
                "1993":16,
                "1994":8,
                "1995":14,
                "1996":3,
                "1997":8,
                "1998":7,
                "1999":11,
                "2000":8,
                "2001":11,
                "2002":18,
                "2003":17,
                "2004":17,
                "2005":17,
                "2006":15,
                "2007":29,
                "2008":22,
                "2009":38,
                "2010":30,
                "2011":26,
                "2012":24,
                "2013":24,
                "2014":16,
                "2015":13,
                "2016":21,
                "2017":13,
                "2018":15,
                "2019":13,
                "2020":20,
                "2021":3
            }
        ],
        [
            "We provide the first optimal algorithms in terms of the number of input\/outputs (I\/Os) required between internal memory and multiple secondary storage devices for the problems of sorting, FFT, matrix transposition, standard matrix multiplication, and related problems. Our two-level memory model is new and gives a realistic treatmentof parallel block transfer, in which during a single I\/O each of theP secondary storage devices can simultaneously transfer a contiguous block ofB records. The model pertains to a large-scale uniprocessor system or parallel multiprocessor system withP disks. In addition, the sorting, FFT, permutation network, and standard matrix multiplication algorithms are typically optimal in terms of the amount of internal processing time. The difficulty in developing optimal algorithms is to cope with the partitioning of memory intoP separate physical devices. Our algorithms' performances can be \u2026",
            "Algorithms for parallel memory, I: Two-level memories",
            "Jeffrey Scott Vitter and Elizabeth AM Shriver",
            "1994",
            "IeXW2bkAAAAJ:9yKSN-GCB0IC",
            500,
            "https:\/\/link.springer.com\/article\/10.1007\/BF01185207",
            "2657759896627365517",
            "\/scholar?cites=2657759896627365517",
            {
                "1993":7,
                "1994":5,
                "1995":14,
                "1996":24,
                "1997":19,
                "1998":29,
                "1999":52,
                "2000":21,
                "2001":33,
                "2002":30,
                "2003":25,
                "2004":26,
                "2005":26,
                "2006":18,
                "2007":30,
                "2008":17,
                "2009":14,
                "2010":21,
                "2011":14,
                "2012":10,
                "2013":9,
                "2014":9,
                "2015":6,
                "2016":5,
                "2017":8,
                "2018":6,
                "2019":5,
                "2020":2
            }
        ],
        [
            "Computing multidimensional aggregates in high dimensions is a performance bottleneck for many OLAP applications. Obtaining the exact answer to an aggregation query can be prohibitively expensive in terms of time and\/or storage space in a data warehouse environment. It is advantageous to have fast, approximate answers to OLAP aggregation queries.In this paper, we present a novel method that provides approximate answers to high-dimensional OLAP aggregation queries in massive sparse data sets in a time-efficient and space-efficient manner. We construct a compact data cube, which is an approximate and space-efficient representation of the underlying multidimensional array, based upon a multiresolution wavelet decomposition. In the on-line phase, each aggregation query can generally be answered using the compact data cube in one I\/O or a smalll number of I\/Os, depending upon the desired \u2026",
            "Approximate computation of multidimensional aggregates of sparse data using wavelets",
            "Jeffrey Scott Vitter and Min Wang",
            "1999",
            "IeXW2bkAAAAJ:qjMakFHDy7sC",
            488,
            "https:\/\/dl.acm.org\/doi\/abs\/10.1145\/304181.304199",
            "15042500066935150642",
            "\/scholar?cites=15042500066935150642",
            {
                "1998":2,
                "1999":3,
                "2000":19,
                "2001":24,
                "2002":28,
                "2003":35,
                "2004":33,
                "2005":45,
                "2006":45,
                "2007":51,
                "2008":29,
                "2009":32,
                "2010":18,
                "2011":23,
                "2012":12,
                "2013":11,
                "2014":7,
                "2015":13,
                "2016":12,
                "2017":11,
                "2018":8,
                "2019":11,
                "2020":8
            }
        ],
        [
            "We present a collection of new techniques for designing and analyzing efficient external-memory algorithms for graph problems and illustrate how these techniques can be applied to a wide variety of specific problems. Our results include: Proximate-neighboring. We present a simple method for deriving external-memory lower bounds via reductions from a problem we call the \u201cproximate neighbors\u201d problem. We use this technique to derive non-trivial lower bounds for such problems as list ranking, expression tree evaluation, and connected components. PRAM simulation. We give methods for efficiently simulating PRAM computations in external memory, even for some cases in which the PRAM algorithm is not work-optimal. We apply this to derive a number of optimal (and simple) external-memory graph algorithms. Time-forward processing. We present a general technique for evaluating circuits (or \u201ccircuit-like\u201d computations) in external memory. We also usethis in a deterministic list ranking algorithm. Deterministic 3-coloring of a cycle. We give several optimal methods for 3-coloring a cycle, which can be used as a subroutine for finding large independent sets for list ranking. Our ideas go beyond a straightforward PRAM simulation, and may be of independent interest. External depth-first search. We discuss a method for performing depth first search and solving related problems efficiently in external memory. Our technique can be used in conjunction with ideas due to Ullman and Yannakakis in order to solve graph problems involving closed semi-ring computations even when their assumption that vertices fit in main memory does not hold. Our \u2026",
            "External-memory graph algorithms",
            "Yi-Jen Chiang and Michael T Goodrich and Edward F Grove and Roberto Tamassia and Darren Erik Vengroff and Jeffrey Scott Vitter",
            "1995",
            "IeXW2bkAAAAJ:UeHWp8X0CEIC",
            433,
            "https:\/\/kuscholarworks.ku.edu\/handle\/1808\/7180",
            "1913923486979287736",
            "\/scholar?cites=1913923486979287736",
            {
                "1994":2,
                "1995":10,
                "1996":21,
                "1997":15,
                "1998":16,
                "1999":15,
                "2000":9,
                "2001":18,
                "2002":21,
                "2003":16,
                "2004":32,
                "2005":17,
                "2006":28,
                "2007":27,
                "2008":16,
                "2009":20,
                "2010":22,
                "2011":16,
                "2012":15,
                "2013":17,
                "2014":16,
                "2015":19,
                "2016":8,
                "2017":10,
                "2018":7,
                "2019":7,
                "2020":4
            }
        ]
    ]
}