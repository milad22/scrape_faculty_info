{
    "columns":[
        "abstract",
        "title",
        "author",
        "pub_year",
        "author_pub_id",
        "num_citations",
        "pub_url",
        "cites_id",
        "citedby_url",
        "cites_per_year"
    ],
    "index":[
        0,
        1,
        2
    ],
    "data":[
        [
            "Image quality assessment (IQA) aims to use computational models to measure the image quality consistently with subjective evaluations. The well-known structural similarity index brings IQA from pixel- to structure-based stage. In this paper, a novel feature similarity (FSIM) index for full reference IQA is proposed based on the fact that human visual system (HVS) understands an image mainly according to its low-level features. Specifically, the phase congruency (PC), which is a dimensionless measure of the significance of a local structure, is used as the primary feature in FSIM. Considering that PC is contrast invariant while the contrast information does affect HVS' perception of image quality, the image gradient magnitude (GM) is employed as the secondary feature in FSIM. PC and GM play complementary roles in characterizing the image local quality. After obtaining the local quality map, we use PC again as a \u2026",
            "FSIM: A feature similarity index for image quality assessment",
            "Lin Zhang and Lei Zhang and X Mou and D Zhang",
            "2011",
            "tAK5l1IAAAAJ:QYdC8u9Cj1oC",
            3050,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/5705575\/",
            "10173695476098164994",
            "\/scholar?cites=10173695476098164994",
            {
                "2011":28,
                "2012":82,
                "2013":108,
                "2014":214,
                "2015":299,
                "2016":393,
                "2017":402,
                "2018":465,
                "2019":466,
                "2020":512,
                "2021":33
            }
        ],
        [
            "The discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise at a certain noise level, our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e., blind Gaussian denoising). With the residual learning strategy, DnCNN implicitly removes the latent clean image in the hidden \u2026",
            "Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising",
            "Kai Zhang and Wangmeng Zuo and Yunjin Chen and Deyu Meng and Lei Zhang",
            "2017",
            "tAK5l1IAAAAJ:LGlY6t8CeOMC",
            2720,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/7839189\/",
            "8389787286584772945",
            "\/scholar?cites=8389787286584772945",
            {
                "2017":110,
                "2018":481,
                "2019":851,
                "2020":1154,
                "2021":91
            }
        ],
        [
            "It is a challenging task to develop effective and efficient appearance models for robust object tracking due to factors such as pose variation, illumination change, occlusion, and motion blur. Existing online tracking algorithms often update models with samples from observations in recent frames. Despite much success has been demonstrated, numerous issues remain to be addressed. First, while these adaptive appearance models are data-dependent, there does not exist sufficient amount of data for online algorithms to learn at the outset. Second, online tracking algorithms often encounter the drift problems. As a result of self-taught learning, misaligned samples are likely to be added and degrade the appearance models. In this paper, we propose a simple yet effective and efficient tracking algorithm with an appearance model based on features extracted from a multiscale image feature space with dataindependent \u2026",
            "Fast compressive tracking",
            "Kaihua Zhang and Lei Zhang and Ming-Hsuan Yang",
            "2014",
            "tAK5l1IAAAAJ:R22Rs3tN8aoC",
            2236,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/6784124\/",
            "3292043029527210151",
            "\/scholar?cites=3292043029527210151",
            {
                "2013":104,
                "2014":249,
                "2015":383,
                "2016":440,
                "2017":345,
                "2018":305,
                "2019":210,
                "2020":134,
                "2021":13
            }
        ]
    ]
}