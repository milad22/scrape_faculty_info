{
    "columns":[
        "abstract",
        "title",
        "author",
        "pub_year",
        "author_pub_id",
        "num_citations",
        "pub_url",
        "cites_id",
        "citedby_url",
        "cites_per_year"
    ],
    "index":[
        0,
        1,
        2,
        3,
        4,
        5
    ],
    "data":[
        [
            "There has been a long controversy as to whether subjectively'free'decisions are determined by brain activity ahead of time. We found that the outcome of a decision can be encoded in brain activity of prefrontal and parietal cortex up to 10 s before it enters awareness. This delay presumably reflects the operation of a network of high-level control areas that begin to prepare an upcoming decision long before it enters awareness.",
            "Unconscious determinants of free decisions in the human brain",
            "Chun Siong Soon and Marcel Brass and Hans-Jochen Heinze and John-Dylan Haynes",
            "2008",
            "pPRLye4AAAAJ:u-x6o8ySG0sC",
            1991,
            "https:\/\/www.nature.com\/articles\/nn.2112?source=post_page---------------------------",
            "5481969984513278414",
            "\/scholar?cites=5481969984513278414",
            {
                "2008":23,
                "2009":87,
                "2010":117,
                "2011":132,
                "2012":200,
                "2013":183,
                "2014":187,
                "2015":133,
                "2016":183,
                "2017":172,
                "2018":144,
                "2019":157,
                "2020":122,
                "2021":11
            }
        ],
        [
            "Recent advances in human neuroimaging have shown that it is possible to accurately decode a person's conscious experience based only on non-invasive measurements of their brain activity. Such'brain reading'has mostly been studied in the domain of visual perception, where it helps reveal the way in which individual experiences are encoded in the human brain. The same approach can also be extended to other types of mental state, such as covert attitudes and lie detection. Such applications raise important ethical issues concerning the privacy of personal thought.",
            "Decoding mental states from brain activity in humans",
            "John-Dylan Haynes and Geraint Rees",
            "2006",
            "pPRLye4AAAAJ:u5HHmVD_uO8C",
            1865,
            "https:\/\/www.nature.com\/articles\/nrn1931",
            "16403222224428366602",
            "\/scholar?cites=16403222224428366602",
            {
                "2006":8,
                "2007":50,
                "2008":86,
                "2009":115,
                "2010":134,
                "2011":186,
                "2012":199,
                "2013":166,
                "2014":165,
                "2015":152,
                "2016":103,
                "2017":133,
                "2018":121,
                "2019":117,
                "2020":97,
                "2021":7
            }
        ],
        [
            "Humans can experience aftereffects from oriented stimuli that are not consciously perceived, suggesting that such stimuli receive cortical processing. Determining the physiological substrate of such effects has proven elusive owing to the low spatial resolution of conventional human neuroimaging techniques compared to the size of orientation columns in visual cortex. Here we show that even at conventional resolutions it is possible to use fMRI to obtain a direct measure of orientation-selective processing in V1. We found that many parts of V1 show subtle but reproducible biases to oriented stimuli, and that we could accumulate this information across the whole of V1 using multivariate pattern recognition. Using this information, we could then successfully predict which one of two oriented stimuli a participant was viewing, even when masking rendered that stimulus invisible. Our findings show that conventional fMRI \u2026",
            "Predicting the orientation of invisible stimuli from activity in human primary visual cortex",
            "John-Dylan Haynes and Geraint Rees",
            "2005",
            "pPRLye4AAAAJ:d1gkVwhDpl0C",
            900,
            "https:\/\/www.nature.com\/articles\/nn1445",
            "12976141024760787660",
            "\/scholar?cites=12976141024760787660",
            {
                "2005":17,
                "2006":33,
                "2007":52,
                "2008":44,
                "2009":71,
                "2010":76,
                "2011":95,
                "2012":92,
                "2013":77,
                "2014":56,
                "2015":60,
                "2016":53,
                "2017":48,
                "2018":42,
                "2019":38,
                "2020":34,
                "2021":4
            }
        ],
        [
            "When humans are engaged in goal-related processing, activity in prefrontal cortex is increased 1, 2. However, it has remained unclear whether this prefrontal activity encodes a subject's current intention [3]. Instead, increased levels of activity could reflect preparation of motor responses 4, 5, holding in mind a set of potential choices [6], tracking the memory of previous responses [7], or general processes related to establishing a new task set. Here we study subjects who freely decided which of two tasks to perform and covertly held onto an intention during a variable delay. Only after this delay did they perform the chosen task and indicate which task they had prepared. We demonstrate that during the delay, it is possible to decode from activity in medial and lateral regions of prefrontal cortex which of two tasks the subjects were covertly intending to perform. This suggests that covert goals can be represented by \u2026",
            "Reading hidden intentions in the human brain",
            "John-Dylan Haynes and Katsuyuki Sakai and Geraint Rees and Sam Gilbert and Chris Frith and Richard E Passingham",
            "2007",
            "pPRLye4AAAAJ:9yKSN-GCB0IC",
            768,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0960982206026583",
            "14805322240870672638",
            "\/scholar?cites=14805322240870672638",
            {
                "2007":17,
                "2008":48,
                "2009":68,
                "2010":69,
                "2011":91,
                "2012":84,
                "2013":65,
                "2014":59,
                "2015":51,
                "2016":40,
                "2017":52,
                "2018":37,
                "2019":32,
                "2020":34,
                "2021":5
            }
        ],
        [
            "The increase in spatiotemporal resolution of neuroimaging devices is accompanied by a trend towards more powerful multivariate analysis methods. Often it is desired to interpret the outcome of these methods with respect to the cognitive processes under study. Here we discuss which methods allow for such interpretations, and provide guidelines for choosing an appropriate analysis for a given experimental goal: For a surgeon who needs to decide where to remove brain tissue it is most important to determine the origin of cognitive functions and associated neural processes. In contrast, when communicating with paralyzed or comatose patients via brain\u2013computer interfaces, it is most important to accurately extract the neural processes specific to a certain mental state. These equally important but complementary objectives require different analysis methods. Determining the origin of neural processes in time or \u2026",
            "On the interpretation of weight vectors of linear models in multivariate neuroimaging",
            "Stefan Haufe and Frank Meinecke and Kai G\u00f6rgen and Sven D\u00e4hne and John-Dylan Haynes and Benjamin Blankertz and Felix Bie\u00dfmann",
            "2014",
            "pPRLye4AAAAJ:aqlVkmm33-oC",
            701,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/S1053811913010914",
            "8326441264045714796",
            "\/scholar?cites=8326441264045714796",
            {
                "2013":2,
                "2014":34,
                "2015":62,
                "2016":69,
                "2017":108,
                "2018":119,
                "2019":142,
                "2020":147,
                "2021":13
            }
        ],
        [
            "Regions in human frontal cortex may have modulatory top-down influences on retinotopic visual cortex, but to date neuroimaging methods have only been able to provide indirect evidence for such functional interactions between remote but interconnected brain regions. Here we combined transcranial magnetic stimulation (TMS) with concurrent functional magnetic resonance imaging (fMRI), plus psychophysics, to show that stimulation of the right human frontal eye-field (FEF) produced a characteristic topographic pattern of activity changes in retinotopic visual areas V1-V4, with functional consequences for visual perception.FEF TMS led to activity increases for retinotopic representations of the peripheral visual field, but to activity decreases for the central field, in areas V1-V4. These frontal influences on visual cortex occurred in a top-down manner, independently of visual input. TMS of a control \u2026",
            "Concurrent TMS-fMRI and psychophysics reveal frontal influences on human retinotopic visual cortex",
            "Christian C Ruff and Felix Blankenburg and Otto Bjoertomt and Sven Bestmann and Elliot Freeman and John-Dylan Haynes and Geraint Rees and Oliver Josephs and Ralf Deichmann and Jon Driver",
            "2006",
            "pPRLye4AAAAJ:2osOgNQ5qMEC",
            487,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0960982206018185",
            "975984324737297703",
            "\/scholar?cites=975984324737297703",
            {
                "2006":3,
                "2007":25,
                "2008":36,
                "2009":32,
                "2010":47,
                "2011":45,
                "2012":46,
                "2013":43,
                "2014":40,
                "2015":28,
                "2016":18,
                "2017":33,
                "2018":27,
                "2019":34,
                "2020":24,
                "2021":3
            }
        ]
    ]
}