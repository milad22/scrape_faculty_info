{
    "columns":[
        "abstract",
        "title",
        "author",
        "pub_year",
        "author_pub_id",
        "num_citations",
        "pub_url",
        "cites_id",
        "citedby_url",
        "cites_per_year"
    ],
    "index":[
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "data":[
        [
            "This paper presents and characterizes Rodinia, a benchmark suite for heterogeneous computing. To help architects study emerging platforms such as GPUs (Graphics Processing Units), Rodinia includes applications and kernels which target multi-core CPU and GPU platforms. The choice of applications is inspired by Berkeley's dwarf taxonomy. Our characterization shows that the Rodinia benchmarks cover a wide range of parallel communication patterns, synchronization techniques and power consumption, and has led to some important architectural insight, such as the growing importance of memory-bandwidth limitations and the consequent importance of data layout.",
            "Rodinia: A benchmark suite for heterogeneous computing",
            "Shuai Che and Michael Boyer and Jiayuan Meng and David Tarjan and Jeremy W Sheaffer and Sang-Ha Lee and Kevin Skadron",
            "2009",
            "mDhldqAAAAAJ:u-x6o8ySG0sC",
            2733,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/5306797\/",
            "2195783173124270427",
            "\/scholar?cites=2195783173124270427",
            {
                "2008":10,
                "2009":10,
                "2010":46,
                "2011":78,
                "2012":129,
                "2013":166,
                "2014":253,
                "2015":317,
                "2016":316,
                "2017":330,
                "2018":364,
                "2019":333,
                "2020":280,
                "2021":10
            }
        ],
        [
            "Graphics processors (GPUs) provide a vast number of simple, data-parallel, deeply multithreaded cores and high memory bandwidths. GPU architectures are becoming increasingly programmable, offering the potential for dramatic speedups for a variety of general-purpose applications compared to contemporary general-purpose processors (CPUs). This paper uses NVIDIA\u2019s C-like CUDA language and an engineering sample of their recently introduced GTX 260 GPU to explore the effectiveness of GPUs for a variety of application types, and describes some specific coding idioms that improve their performance on the GPU. GPU performance is compared to both single-core and multicore CPU performance, with multicore CPU implementations written using OpenMP. The paper also discusses advantages and inefficiencies of the CUDA programming model and some desirable features that might allow for greater \u2026",
            "A performance study of general-purpose applications on graphics processors using CUDA",
            "Shuai Che and Michael Boyer and Jiayuan Meng and David Tarjan and Jeremy W Sheaffer and Kevin Skadron",
            "2008",
            "mDhldqAAAAAJ:u5HHmVD_uO8C",
            826,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0743731508000932",
            "8420156248872827552",
            "\/scholar?cites=8420156248872827552",
            {
                "2007":3,
                "2008":7,
                "2009":58,
                "2010":89,
                "2011":93,
                "2012":85,
                "2013":102,
                "2014":91,
                "2015":75,
                "2016":63,
                "2017":53,
                "2018":35,
                "2019":37,
                "2020":18
            }
        ],
        [
            "The recently released Rodinia benchmark suite enables users to evaluate heterogeneous systems including both accelerators, such as GPUs, and multicore CPUs. As Rodinia sees higher levels of acceptance, it becomes important that researchers understand this new set of benchmarks, especially in how they differ from previous work. In this paper, we present recent extensions to Rodinia and conduct a detailed characterization of the Rodinia benchmarks (including performance results on an NVIDIA GeForce GTX480, the first product released based on the Fermi architecture). We also compare and contrast Rodinia with Parsec to gain insights into the similarities and differences of the two benchmark collections; we apply principal component analysis to analyze the application space coverage of the two suites. Our analysis shows that many of the workloads in Rodinia and Parsec are complementary, capturing \u2026",
            "A characterization of the Rodinia benchmark suite with comparison to contemporary CMP workloads",
            "Shuai Che and Jeremy W Sheaffer and Michael Boyer and Lukasz G Szafaryn and Liang Wang and Kevin Skadron",
            "2010",
            "mDhldqAAAAAJ:UeHWp8X0CEIC",
            349,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/5650274\/",
            "7268609386456362969",
            "\/scholar?cites=7268609386456362969",
            {
                "2010":1,
                "2011":6,
                "2012":13,
                "2013":22,
                "2014":43,
                "2015":48,
                "2016":42,
                "2017":52,
                "2018":47,
                "2019":36,
                "2020":24
            }
        ],
        [
            "Recent increases in the programmability and performance of GPUs have led to a surge of interest in utilizing them for general-purpose computations. Tools such as NVIDIA\u2019s Cuda allow programmers to use a C-like language to code algorithms for execution on the GPU. Unfortunately, parallel programs are prone to subtle correctness and performance bugs, and Cuda tool support for solving these remains a work in progress.As a first step towards addressing these problems, we present an automated analysis technique for finding two specific classes of bugs in Cuda programs: race conditions, which impact program correctness, and shared memory bank conflicts, which impact program performance. Our technique automatically instruments a program in two ways: to keep track of the memory locations accessed by different threads, and to use this data to determine whether bugs exist in the program. The instrumented source code can be run directly in Cuda\u2019s device emulation mode, and any potential errors discovered will be automatically reported to the user. This automated analysis can help programmers find and solve subtle bugs in programs that are too complex to analyze manually. Although these issues are explored in the context of Cuda programs, similar issues will arise in any sufficiently \u201cmanycore\u201d architecture.",
            "Automated dynamic analysis of CUDA programs",
            "Michael Boyer and Kevin Skadron and Westley Weimer",
            "2008",
            "mDhldqAAAAAJ:d1gkVwhDpl0C",
            124,
            "http:\/\/www.cs.virginia.edu\/~skadron\/Papers\/stmcs08.pdf",
            "4437974942021032655",
            "\/scholar?cites=4437974942021032655",
            {
                "2007":2,
                "2008":3,
                "2009":10,
                "2010":9,
                "2011":20,
                "2012":14,
                "2013":12,
                "2014":11,
                "2015":14,
                "2016":6,
                "2017":5,
                "2018":5,
                "2019":3,
                "2020":3,
                "2021":1
            }
        ],
        [
            "The availability of easily programmable manycore CPUs and GPUs has motivated investigations into how to best exploit their tremendous computational power for scientific computing. Here we demonstrate how a systems biology application - detection and tracking of white blood cells in video microscopy - can be accelerated by 200times using a CUDA-capable GPU. Because the algorithms and implementation challenges are common to a wide range of applications, we discuss general techniques that allow programmers to make efficient use of a manycore GPU.",
            "Accelerating leukocyte tracking using CUDA: A case study in leveraging manycore coprocessors",
            "Michael Boyer and David Tarjan and Scott T Acton and Kevin Skadron",
            "2009",
            "mDhldqAAAAAJ:9yKSN-GCB0IC",
            84,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/5160984\/",
            "4543775344577722289",
            "\/scholar?cites=4543775344577722289",
            {
                "2009":9,
                "2010":14,
                "2011":11,
                "2012":7,
                "2013":4,
                "2014":11,
                "2015":9,
                "2016":9,
                "2017":6,
                "2018":2,
                "2019":1
            }
        ],
        [
            "Fully utilizing the power of modern heterogeneous systems requires judiciously dividing work across all of the available computational devices. Existing approaches for partitioning work require offline training and generate fixed partitions that fail to respond to fluctuations in device performance that occur at run time. We present a novel dynamic approach to work partitioning that requires no offline training and responds automatically to performance variability to provide consistently good performance. Using six diverse OpenCL\u2122 applications, we demonstrate the effectiveness of our approach in scenarios both with and without run-time performance variability, as well as in more extreme scenarios in which one device is non-functional.",
            "Load Balancing in a Changing World: Dealing with Heterogeneity and Performance Variability",
            "Michael Boyer and Kevin Skadron and Shuai Che and Nuwan Jayasena",
            "2013",
            "mDhldqAAAAAJ:ufrVoPGSRksC",
            74,
            "https:\/\/dl.acm.org\/doi\/abs\/10.1145\/2482767.2482794",
            "4063153812403991012",
            "\/scholar?cites=4063153812403991012",
            {
                "2012":1,
                "2013":6,
                "2014":7,
                "2015":15,
                "2016":11,
                "2017":8,
                "2018":10,
                "2019":5,
                "2020":9
            }
        ],
        [
            "Accelerators such as graphics processors (GPUs) have become increasingly popular for high performance scientific computing. Often, much effort is invested in creating and optimizing GPU code without any guaranteed performance benefit. To reduce this risk, performance models can be used to project a kernel's GPU performance potential before it is ported. However, raw GPU execution time is not the only consideration. The overhead of transferring data between the CPU and the GPU is also an important factor; for some applications, this overhead may even erase the performance benefits of GPU acceleration. To address this challenge, we propose a GPU performance modeling framework that predicts both kernel execution time and data transfer time. Our extensions to an existing GPU performance model include a data usage analyzer for a sequence of GPU kernels, to determine the amount of data that needs \u2026",
            "Improving GPU Performance Prediction with Data Transfer Modeling",
            "Michael Boyer and Jiayuan Meng and Kalyan Kumaran",
            "2013",
            "mDhldqAAAAAJ:WF5omc3nYNoC",
            67,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/6650995\/",
            "7288110618498990759",
            "\/scholar?cites=7288110618498990759",
            {
                "2014":9,
                "2015":10,
                "2016":10,
                "2017":8,
                "2018":11,
                "2019":8,
                "2020":7,
                "2021":1
            }
        ],
        [
            "Heterogeneous systems often employ processing units with a wide spectrum of performance capabilities. Allowing individual applications to make greedy local scheduling decisions leads to imbalance, with underutilization of some devices and excessive contention for others. If we instead allow the system to make global scheduling decisions and assign some applications to a slower device, we can both increase overall system throughput and decrease individual application runtimes.We present a method for dynamically scheduling applications running on heterogeneous platforms in order to maximize overall throughput. The key to our approach is accurately estimating when an application would finish execution on a given device based on historical runtime information, allowing us to make scheduling decisions that are both globally and locally efficient. We evaluate our approach with a set of OpenCL applications running on a system with a multicore CPU and a discrete GPU. We show that scheduling decisions based on historical data can decrease the total runtime by 39% over GPU-only scheduling and 29% over scheduling that places each application on its preferred device.",
            "Dynamic Heterogeneous Scheduling Decisions Using Historical Runtime Data",
            "Chris Gregg and Michael Boyer and Kim Hazelwood and Kevin Skadron",
            "2011",
            "mDhldqAAAAAJ:Tyk-4Ss8FVUC",
            67,
            "https:\/\/www.cs.virginia.edu\/~skadron\/Papers\/gregg_a4mmc11.pdf",
            "12095368425931350103",
            "\/scholar?cites=12095368425931350103",
            {
                "2012":4,
                "2013":9,
                "2014":6,
                "2015":11,
                "2016":6,
                "2017":6,
                "2018":6,
                "2019":10,
                "2020":6
            }
        ],
        [
            "Future SoCs will contain multiple cores. For workloads with significant parallelism, prior work has shown the benefit of many small, multi-threaded, scalar cores. For workloads that require better single-thread performance, a dedicated, larger core can help but comes at a large opportunity cost in the number of scalar cores that could be provisioned instead. This paper proposes a way to repurpose a pair of scalar cores into a 2-way out-of-order issue core with minimal area overhead. \"Federating\" scalar cores in this way nevertheless achieves comparable performance to a dedicated out-of-order core and dissipates less power as well.",
            "Federation: Repurposing scalar cores for out-of-order instruction issue",
            "David Tarjan and Michael Boyer and Kevin Skadron",
            "2008",
            "mDhldqAAAAAJ:2osOgNQ5qMEC",
            64,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/4555923\/",
            "8895696444653081904",
            "\/scholar?cites=8895696444653081904",
            {
                "2008":1,
                "2009":4,
                "2010":10,
                "2011":6,
                "2012":5,
                "2013":13,
                "2014":4,
                "2015":4,
                "2016":5,
                "2017":4,
                "2018":5,
                "2019":1
            }
        ],
        [
            "Modern CPUs employ Dynamic Voltage and Frequency Scaling (DVFS) to boost performance, lower power, and improve energy efficiency. Good DVFS decisions require accurate performance predictions across frequencies. A new hardware structure for measuring leading load cycles was recently proposed and demonstrated promising performance prediction abilities in simulation.",
            "Implementing a leading loads performance predictor on commodity processors",
            "Bo Su and Joseph L Greathouse and Junli Gu and Michael Boyer and Li Shen and Zhiying Wang",
            "2014",
            "mDhldqAAAAAJ:LkGwnXOMwfcC",
            38,
            "https:\/\/www.usenix.org\/conference\/atc14\/technical-sessions\/presentation\/su",
            "2889299025052550623",
            "\/scholar?cites=2889299025052550623",
            {
                "2014":1,
                "2015":10,
                "2016":7,
                "2017":8,
                "2018":4,
                "2019":3,
                "2020":2
            }
        ]
    ]
}