{
    "columns":[
        "abstract",
        "title",
        "author",
        "pub_year",
        "author_pub_id",
        "num_citations",
        "pub_url",
        "cites_id",
        "citedby_url",
        "cites_per_year"
    ],
    "index":[
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "data":[
        [
            "In an effort to elucidate the molecular mechanisms underlying cerebral vascular alteration after stroke, the authors measured the spatial and temporal profiles of blood\u2013brain barrier (BBB) leakage, angiogenesis, vascular endothelial growth factor (VEGF), associated receptors, and angiopoietins and receptors after embolic stroke in the rat. Two to four hours after onset of ischemia, VEGF mRNA increased, whereas angiopoietin 1 (Ang 1) mRNA decreased. Three-dimensional immunofluorescent analysis revealed spatial coincidence between increases of VEGF immunoreactivity and BBB leakage in the ischemic core. Two to 28 days after the onset of stroke, increased expression of VEGF\/VEGF receptors and Ang\/Tie2 was detected at the boundary of the ischemic lesion. Concurrently, enlarged and thin-walled vessels were detected at the boundary of the ischemic lesion, and these vessels developed into smaller \u2026",
            "Correlation of VEGF and angiopoietin expression with disruption of blood\u2013brain barrier and angiogenesis after focal cerebral ischemia",
            "Zheng Gang Zhang and Li Zhang and Wayne Tsang and Hamid Soltanian-Zadeh and Daniel Morris and Ruilan Zhang and Anton Goussev and Cecylia Powers and Thomas Yeich and Michael Chopp",
            "2002",
            "Lc1LZWIAAAAJ:u5HHmVD_uO8C",
            549,
            "https:\/\/journals.sagepub.com\/doi\/abs\/10.1097\/00004647-200204000-00002",
            "15904065468854069225",
            "\/scholar?cites=15904065468854069225",
            {
                "2002":3,
                "2003":21,
                "2004":22,
                "2005":26,
                "2006":33,
                "2007":30,
                "2008":35,
                "2009":36,
                "2010":32,
                "2011":30,
                "2012":34,
                "2013":38,
                "2014":44,
                "2015":33,
                "2016":35,
                "2017":29,
                "2018":17,
                "2019":25,
                "2020":25
            }
        ],
        [
            "This paper presents a new approach to rotation invariant texture classification. The proposed approach benefits from the fact that most of the texture patterns either have directionality (anisotropic textures) or are not with a specific direction (isotropic textures). The wavelet energy features of the directional textures change significantly when the image is rotated. However, for the isotropic images, the wavelet features are not sensitive to rotation. Therefore, for the directional textures, it is essential to calculate the wavelet features along a specific direction. In the proposed approach, the Radon transform is first employed to detect the principal direction of the texture. Then, the texture is rotated to place its principal direction at 0 degrees. A wavelet transform is applied to the rotated image to extract texture features. This approach provides a features space with small intraclass variability and, therefore, good separation \u2026",
            "Radon transform orientation estimation for rotation invariant texture analysis",
            "Kourosh Jafari-Khouzani and Hamid Soltanian-Zadeh",
            "2005",
            "Lc1LZWIAAAAJ:d1gkVwhDpl0C",
            335,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/1424459\/",
            "6764383646204894133",
            "\/scholar?cites=6764383646204894133",
            {
                "2005":2,
                "2006":7,
                "2007":13,
                "2008":18,
                "2009":24,
                "2010":30,
                "2011":32,
                "2012":25,
                "2013":23,
                "2014":29,
                "2015":33,
                "2016":18,
                "2017":17,
                "2018":26,
                "2019":23,
                "2020":12
            }
        ],
        [
            "We present an evaluation and comparison of the performance of four different texture and shape feature extraction methods for classification of benign and malignant microcalcifications in mammograms. For 103 regions containing microcalcification clusters, texture and shape features were extracted using four approaches: conventional shape quantifiers; co-occurrence-based method of Haralick; wavelet transformations; and multi-wavelet transformations. For each set of features, most discriminating features and their optimal weights were found using real-valued and binary genetic algorithms (GA) utilizing a k-nearest-neighbor classifier and a malignancy criterion for generating ROC curves for measuring the performance. The best set of features generated areas under the ROC curve ranging from 0.84 to 0.89 when using real-valued GA and from 0.83 to 0.88 when using binary GA. The multi-wavelet method \u2026",
            "Comparison of multiwavelet, wavelet, Haralick, and shape features for microcalcification classification in mammograms",
            "Hamid Soltanian-Zadeh and Farshid Rafiee-Rad",
            "2004",
            "Lc1LZWIAAAAJ:9yKSN-GCB0IC",
            238,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0031320304001323",
            "9924942674545252072",
            "\/scholar?cites=9924942674545252072",
            {
                "2004":1,
                "2005":6,
                "2006":10,
                "2007":15,
                "2008":13,
                "2009":14,
                "2010":21,
                "2011":18,
                "2012":21,
                "2013":19,
                "2014":15,
                "2015":25,
                "2016":16,
                "2017":10,
                "2018":13,
                "2019":10,
                "2020":10
            }
        ],
        [
            "Histological grading of pathological images is used to determine the level of malignancy of cancerous tissues. This is a very important task in prostate cancer prognosis, since it is used for treatment planning. If infection of cancer is not rejected by noninvasive diagnostic techniques like magnetic resonance imaging, computed tomography scan, and ultrasound, then biopsy specimens of tissue are tested. For prostate, biopsied tissue is stained by hematoxyline and eosine method and viewed by pathologists under a microscope to determine its histological grade. Human grading is very subjective due to interobserver and intraobserver variations and in some cases difficult and time-consuming. Thus, an automatic and repeatable technique is needed for grading. The Gleason grading system is the most common method for histological grading of prostate tissue samples. According to this system, each cancerous \u2026",
            "Multiwavelet grading of pathological images of prostate",
            "Kourosh Jafari-Khouzani and Hamid Soltanian-Zadeh",
            "2003",
            "Lc1LZWIAAAAJ:2osOgNQ5qMEC",
            237,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/1203808\/",
            "7711597790662191881",
            "\/scholar?cites=7711597790662191881",
            {
                "2003":2,
                "2004":5,
                "2005":10,
                "2006":5,
                "2007":11,
                "2008":10,
                "2009":20,
                "2010":19,
                "2011":15,
                "2012":12,
                "2013":19,
                "2014":17,
                "2015":25,
                "2016":19,
                "2017":23,
                "2018":9,
                "2019":9,
                "2020":6,
                "2021":1
            }
        ],
        [
            "A new rotation-invariant texture-analysis technique using Radon and wavelet transforms is proposed. This technique utilizes the Radon transform to convert the rotation to translation and then applies a translation-invariant wavelet transform to the result to extract texture features. A k-nearest neighbors classifier is employed to classify texture patterns. A method to find the optimal number of projections for the Radon transform is proposed. It is shown that the extracted features generate an efficient orthogonal feature space. It is also shown that the proposed features extract both of the local and directional information of the texture patterns. The proposed method is robust to additive white noise as a result of summing pixel values to generate projections in the Radon transform step. To test and evaluate the method, we employed several sets of textures along with different wavelet bases. Experimental results show the \u2026",
            "Rotation-invariant multiresolution texture analysis using Radon and wavelet transforms",
            "Kourosh Jafari-Khouzani and Hamid Soltanian-Zadeh",
            "2005",
            "Lc1LZWIAAAAJ:UeHWp8X0CEIC",
            217,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/1430767\/",
            "15673455102486341351",
            "\/scholar?cites=15673455102486341351",
            {
                "2005":4,
                "2006":7,
                "2007":17,
                "2008":21,
                "2009":10,
                "2010":20,
                "2011":29,
                "2012":20,
                "2013":14,
                "2014":17,
                "2015":27,
                "2016":5,
                "2017":12,
                "2018":6,
                "2019":5,
                "2020":3
            }
        ],
        [
            "This paper introduces a new feature vector for shape-based image indexing and retrieval. This feature classifies image edges based on two factors: their orientations and correlation between neighboring edges. Hence it includes information of continuous edges and lines of images and describes major shape properties of images. This scheme is effective and robustly tolerates translation, scaling, color, illumination, and viewing position variations. Experimental results show superiority of proposed scheme over several other indexing methods. Averages of precision and recall rates of this new indexing scheme for retrieval as compared with traditional color histogram are 1.99 and 1.59 times, respectively. These ratios are 1.26 and 1.04 compared to edge direction histogram.",
            "Image retrieval based on shape similarity by edge orientation autocorrelogram",
            "Fariborz Mahmoudi and Jamshid Shanbehzadeh and Amir-Masoud Eftekhari-Moghadam and Hamid Soltanian-Zadeh",
            "2003",
            "Lc1LZWIAAAAJ:IjCSPb-OGe4C",
            215,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0031320303000104",
            "16453284784207439664",
            "\/scholar?cites=16453284784207439664",
            {
                "2003":2,
                "2004":8,
                "2005":7,
                "2006":12,
                "2007":9,
                "2008":10,
                "2009":14,
                "2010":19,
                "2011":9,
                "2012":20,
                "2013":19,
                "2014":20,
                "2015":16,
                "2016":12,
                "2017":10,
                "2018":9,
                "2019":10,
                "2020":5
            }
        ],
        [
            "This paper proposes image processing algorithms to recognize five types of white blood cells in peripheral blood automatically. First, a method based on Gram\u2013Schmidt orthogonalization is proposed along with a snake algorithm to segment nucleus and cytoplasm of the cells. Then, a variety of features are extracted from the segmented regions. Next, most discriminative features are selected using a Sequential Forward Selection (SFS) algorithm and performances of two classifiers, Artificial Neural Network (ANN) and Support Vector Machine (SVM), are compared. The results demonstrate that the proposed methods are accurate and sufficiently fast to be used in hematological laboratories.",
            "Automatic recognition of five types of white blood cells in peripheral blood",
            "Seyed Hamid Rezatofighi and Hamid Soltanian-Zadeh",
            "2011",
            "Lc1LZWIAAAAJ:fEOibwPWpKIC",
            195,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0895611111000048",
            "506637815800747452",
            "\/scholar?cites=506637815800747452",
            {
                "2012":3,
                "2013":3,
                "2014":10,
                "2015":24,
                "2016":18,
                "2017":14,
                "2018":32,
                "2019":34,
                "2020":53,
                "2021":3
            }
        ],
        [
            "Background and Purpose\u2014Using newly developed computerized image analysis, we studied the heterogeneity of apparent diffusion coefficient of water (ADCw) values in human ischemic stroke within 10 hours of onset.Methods\u2014Echo-planar trace diffusion-weighted images from 9 patients with focal cortical ischemic stroke were obtained within 10 hours of symptom onset. An Iterative Self-Organizing Data Analysis (ISODATA) clustering algorithm was implemented to segment different tissue types with a series of DW images. ADCw maps were calculated from 4 DW images on a pixel-by-pixel basis. The segmented zones within the lesion were characterized as low, pseudonormal, or high, expressed as a ratio of the mean\u00b1SD of ADCw of contralateral noninvolved tissue.Results\u2014The average ADCw in the ischemic stroke region within 10 hours of onset was significantly depressed compared with \u2026",
            "Time Course of ADCw Changes in Ischemic Stroke: Beyond the Human Eye!",
            "V Nagesh and KMA Welch and JP Windham and S Patel and SR Levine and D Hearshen and D Peck and K Robbins and L D\u2019Olhaberriague and H Soltanian-Zadeh and MD Boska",
            "1998",
            "Lc1LZWIAAAAJ:u-x6o8ySG0sC",
            155,
            "https:\/\/www.ahajournals.org\/doi\/abs\/10.1161\/01.STR.29.9.1778",
            "4636034058399534191",
            "\/scholar?cites=4636034058399534191",
            {
                "1998":1,
                "1999":12,
                "2000":16,
                "2001":13,
                "2002":14,
                "2003":10,
                "2004":9,
                "2005":11,
                "2006":6,
                "2007":14,
                "2008":4,
                "2009":5,
                "2010":11,
                "2011":7,
                "2012":2,
                "2013":4,
                "2014":2,
                "2015":4,
                "2016":2,
                "2017":5,
                "2018":1,
                "2019":1
            }
        ],
        [
            "Multiple sclerosis (MS) is an inflammatory demyelinating disease that the parts of the nervous system through the lesions generated in the white matter of the brain. It brings about disabilities in different organs of the body such as eyes and muscles. Early detection of MS and estimation of its progression are critical for optimal treatment of the disease.For diagnosis and treatment evaluation of MS lesions, they may be detected and segmented in Magnetic Resonance Imaging (MRI) scans of the brain. However, due to the large amount of MRI data to be analyzed, manual segmentation of the lesions by clinical experts translates into a very cumbersome and time consuming task. In addition, manual segmentation is subjective and prone to human errors. Several groups have developed computerized methods to detect and segment MS \u2026",
            "Segmentation of multiple sclerosis lesions in MR images: a review",
            "Daryoush Mortazavi and Abbas Z Kouzani and Hamid Soltanian-Zadeh",
            "2012",
            "Lc1LZWIAAAAJ:KxtntwgDAa4C",
            142,
            "https:\/\/link.springer.com\/content\/pdf\/10.1007\/s00234-011-0886-7.pdf",
            "12507651437337399810",
            "\/scholar?cites=12507651437337399810",
            {
                "2011":1,
                "2012":7,
                "2013":14,
                "2014":22,
                "2015":23,
                "2016":11,
                "2017":28,
                "2018":10,
                "2019":10,
                "2020":12,
                "2021":2
            }
        ],
        [
            "Recognition of iris based on visible light (VL) imaging is a difficult problem because of the light reflection from the cornea. Nonetheless, pigment melanin provides a rich feature source in VL, which is unavailable in near-infrared (NIR) imaging. This is due to the biological spectroscopy of eumelanin, a chemical not stimulated in NIR. In this case, a plausible solution to observe such patterns may be provided by an adaptive procedure using a variational technique on the image histogram. To describe the patterns, a shape analysis method is used to derive the feature code for each subject. An important question is how the melanin patterns, which are extracted from VL, are independent of the iris texture in NIR. With this question in mind, the present investigation proposes fusion of features extracted from NIR and VL to boost recognition performance. We have collected our own database (UTIRIS), consisting of both NIR \u2026",
            "Pigment melanin: Pattern for iris recognition",
            "Mahdi S Hosseini and Babak N Araabi and Hamid Soltanian-Zadeh",
            "2010",
            "Lc1LZWIAAAAJ:J_g5lzvAfSwC",
            139,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/5427304\/",
            "12995690711673382424",
            "\/scholar?cites=12995690711673382424",
            {
                "2010":3,
                "2011":5,
                "2012":7,
                "2013":9,
                "2014":12,
                "2015":10,
                "2016":18,
                "2017":21,
                "2018":20,
                "2019":14,
                "2020":13,
                "2021":2
            }
        ]
    ]
}