{
    "columns":[
        "abstract",
        "title",
        "author",
        "pub_year",
        "author_pub_id",
        "num_citations",
        "pub_url",
        "cites_id",
        "citedby_url",
        "cites_per_year"
    ],
    "index":[
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "data":[
        [
            "We describe a statistical approach for identifying nonlinearity in time series. The method first specifies some linear process as a null hypothesis, then generates surrogate data sets which are consistent with this null hypothesis, and finally computes a discriminating statistic for the original and for each of the surrogate data sets. If the value computed for the original data is significantly different than the ensemble of values computed for the surrogate data, then the null hypothesis is rejected and nonlinearity is detected. We discuss various null hypotheses and discriminating statistics. The method is demonstrated for numerical data generated by known chaotic systems, and applied to a number of experimental time series which arise in the measurement of superfluids, brain waves, and sunspots; we evaluate the statistical significance of the evidence for nonlinear structure in each case, and illustrate aspects of the data \u2026",
            "Testing for nonlinearity in time series: the method of surrogate data",
            "James Theiler and Stephen Eubank and Andr\u00e9 Longtin and Bryan Galdrikian and J Doyne Farmer",
            "1992",
            "OEjgtVsAAAAJ:Y5dfb0dijaUC",
            4205,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/016727899290102S",
            "12375949362040451047",
            "\/scholar?cites=12375949362040451047",
            {
                "1993":32,
                "1994":47,
                "1995":83,
                "1996":108,
                "1997":101,
                "1998":114,
                "1999":117,
                "2000":143,
                "2001":170,
                "2002":140,
                "2003":139,
                "2004":149,
                "2005":125,
                "2006":157,
                "2007":180,
                "2008":164,
                "2009":184,
                "2010":180,
                "2011":180,
                "2012":172,
                "2013":197,
                "2014":206,
                "2015":184,
                "2016":173,
                "2017":184,
                "2018":192,
                "2019":161,
                "2020":163,
                "2021":14
            }
        ],
        [
            "Most mathematical models for the spread of disease use differential equations based on uniform mixing assumptions 1 or ad hoc models for the contact process 2, 3, 4. Here we explore the use of dynamic bipartite graphs to model the physical contact patterns that result from movements of individuals between specific locations. The graphs are generated by large-scale individual-based urban traffic simulations built on actual census, land-use and population-mobility data. We find that the contact network among people is a strongly connected small-world-like 5 graph with a well-defined scale for the degree distribution. However, the locations graph is scale-free 6, which allows highly efficient outbreak detection by placing sensors in the hubs of the locations network. Within this large-scale simulation framework, we then analyse the relative merits of several proposed mitigation strategies for smallpox spread. Our \u2026",
            "Modelling disease outbreaks in realistic urban social networks",
            "Stephen Eubank and Hasan Guclu and VS Anil Kumar and Madhav V Marathe and Aravind Srinivasan and Zoltan Toroczkai and Nan Wang",
            "2004",
            "OEjgtVsAAAAJ:IjCSPb-OGe4C",
            2026,
            "https:\/\/www.nature.com\/articles\/nature02541?message=remove&lang=en",
            "481590400535028126",
            "\/scholar?cites=481590400535028126",
            {
                "2004":14,
                "2005":47,
                "2006":68,
                "2007":107,
                "2008":81,
                "2009":112,
                "2010":123,
                "2011":145,
                "2012":144,
                "2013":159,
                "2014":154,
                "2015":153,
                "2016":148,
                "2017":102,
                "2018":125,
                "2019":109,
                "2020":191,
                "2021":10
            }
        ],
        [
            "Takens' theorem demonstrates that in the absence of noise a multidimensional state space can be reconstructed from a scalar time series. This theorem gives little guidance, however, about practical considerations for reconstructing a good state space. We extend Takens' treatment, applying statistical methods to incorporate the effects of observational noise and estimation error. We define the distortion matrix, which is proportional to the conditional covariance of a state, given a series of noisy measurements, and the noise amplification, which is proportional to root-square time series prediction errors with an ideal model. We derive explicit formulae for these quantities, and we prove that in the low noise limit minimizing the distortion is equivalent to minimizing the noise amplification.We identify several different scaling regimes for distortion and noise amplification, and derive asymptotic scaling laws. When the \u2026",
            "State space reconstruction in the presence of noise",
            "Martin Casdagli and Stephen Eubank and J Doyne Farmer and John Gibson",
            "1991",
            "OEjgtVsAAAAJ:nb7KW1ujOQ8C",
            700,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/016727899190222U",
            "10282939723885025599",
            "\/scholar?cites=10282939723885025599",
            {
                "1991":3,
                "1992":20,
                "1993":30,
                "1994":23,
                "1995":29,
                "1996":19,
                "1997":32,
                "1998":23,
                "1999":22,
                "2000":24,
                "2001":30,
                "2002":19,
                "2003":20,
                "2004":16,
                "2005":31,
                "2006":16,
                "2007":25,
                "2008":21,
                "2009":23,
                "2010":23,
                "2011":20,
                "2012":10,
                "2013":21,
                "2014":17,
                "2015":30,
                "2016":28,
                "2017":28,
                "2018":32,
                "2019":25,
                "2020":24,
                "2021":2
            }
        ],
        [
            "Planning a response to an outbreak of a pandemic strain of influenza is a high public health priority. Three research groups using different individual-based, stochastic simulation models have examined the consequences of intervention strategies chosen in consultation with U.S. public health workers. The first goal is to simulate the effectiveness of a set of potentially feasible intervention strategies. Combinations called targeted layered containment (TLC) of influenza antiviral treatment and prophylaxis and nonpharmaceutical interventions of quarantine, isolation, school closure, community social distancing, and workplace social distancing are considered. The second goal is to examine the robustness of the results to model assumptions. The comparisons focus on a pandemic outbreak in a population similar to that of Chicago, with \u22488.6 million people. The simulations suggest that at the expected transmissibility of \u2026",
            "Modeling targeted layered containment of an influenza pandemic in the United States",
            "M Elizabeth Halloran and Neil M Ferguson and Stephen Eubank and Ira M Longini and Derek AT Cummings and Bryan Lewis and Shufu Xu and Christophe Fraser and Anil Vullikanti and Timothy C Germann and Diane Wagener and Richard Beckman and Kai Kadau and Chris Barrett and Catherine A Macken and Donald S Burke and Philip Cooley",
            "2008",
            "OEjgtVsAAAAJ:hFOr9nPyWt4C",
            636,
            "https:\/\/www.pnas.org\/content\/105\/12\/4639.short",
            "4829787114898543697",
            "\/scholar?cites=4829787114898543697",
            {
                "2008":10,
                "2009":64,
                "2010":64,
                "2011":56,
                "2012":54,
                "2013":63,
                "2014":36,
                "2015":40,
                "2016":41,
                "2017":31,
                "2018":30,
                "2019":34,
                "2020":94,
                "2021":1
            }
        ],
        [
            "Preventing and controlling outbreaks of infectious diseases such as pandemic influenza is a top public health priority. We describe EpiSimdemics - a scalable parallel algorithm to simulate the spread of contagion in large, realistic social contact networks using individual-based models. EpiSimdemics is an interaction-based simulation of a certain class of stochastic reaction-diffusion processes. Straightforward simulations of such process do not scale well, limiting the use of individual-based models to very small populations. EpiSimdemics is specifically designed to scale to social networks with 100 million individuals. The scaling is obtained by exploiting the semantics of disease evolution and disease propagation in large networks. We evaluate an MPI-based parallel implementation of EpiSimdemics on a mid-sized HPC system, demonstrating that EpiSimdemics scales well. EpiSimdemics has been used in \u2026",
            "EpiSimdemics: an efficient algorithm for simulating the spread of infectious disease over large realistic social networks",
            "Christopher L Barrett and Keith R Bisset and Stephen G Eubank and Xizhou Feng and Madhav V Marathe",
            "2008",
            "OEjgtVsAAAAJ:YFjsv_pBGBYC",
            325,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/5214892\/",
            "6718203628903379306",
            "\/scholar?cites=6718203628903379306",
            {
                "2007":2,
                "2008":11,
                "2009":16,
                "2010":37,
                "2011":37,
                "2012":34,
                "2013":33,
                "2014":32,
                "2015":22,
                "2016":28,
                "2017":13,
                "2018":19,
                "2019":29,
                "2020":1
            }
        ],
        [
            "The interdisciplinary field of nonlinear modeling has grown rapidly over the last decade due to the increasing availability of computer resources, which allows for the collection of increasingly large data sets and the analysis of the data sets with numerically intensive algorithms. In addition, the field has also grown with the increasing recognition of the ubiquity and importance of the effects of nonlinear dynamics in the natural and social sciences. Based on a Santa Fe Institute and NATO sponsored workshop, this book brings together the ideas of leading researchers in this rapidly expanding, interdisciplinary field in an attempt to stimulate the cross-fertilization of ideas and the search for unifying themes. The central theme of the workshop was the construction of nonlinear models from time-series data. Approaches to this problem have drawn from the disciplines of multivariate function approximation and neural nets, dynamical systems and chaos, statistics, information theory, and control theory. Applications have been made to economics, mechanical engineering, meteorology, speech processing, biology, and fluid dynamics. The papers included discuss various approaches to nonlinear multivariate function approximation, statistical issues in time-series analysis, invariants associated with chaotic attractors, and extimation of invariants. Finally, the last seven papers discuss applications to a variety of time-series data using nonlinear modeling and forecasting ideas developed by the authors themselves.",
            "Nonlinear modeling and forecasting",
            "Martin Casdagli",
            "1992",
            "OEjgtVsAAAAJ:_Qo2XoVZTnwC",
            289,
            "http:\/\/scholar.google.com\/scholar?cluster=5320719260794027071&hl=en&oi=scholarr",
            "5320719260794027071",
            "\/scholar?cites=5320719260794027071",
            {
                "1991":1,
                "1992":2,
                "1993":4,
                "1994":10,
                "1995":13,
                "1996":16,
                "1997":22,
                "1998":16,
                "1999":21,
                "2000":14,
                "2001":11,
                "2002":15,
                "2003":10,
                "2004":13,
                "2005":9,
                "2006":17,
                "2007":15,
                "2008":6,
                "2009":10,
                "2010":7,
                "2011":7,
                "2012":5,
                "2013":7,
                "2014":9,
                "2015":4,
                "2016":4,
                "2017":3,
                "2018":6,
                "2019":1,
                "2020":2
            }
        ],
        [
            "We address the issue of reliably discriminating between chaos and noise from a time series. In particular, we are interested in avoiding claims of chaos when simpler models (such as linearly correlated noise) can explain the data. We take a statistical approach, and use a form of bootstrapping to detect nonlinearity by showing that a given linear model is unlikely to have produced the data. Our method requires the careful statement of a null hypothesis which characterizes a candidate linear process, the generation of an ensemble of surrogate''data sets which are similar to the original time series but consistent with the null hypothesis, and the computation of a discriminating statistic for the original and for each of the surrogate data sets. The idea is to test the original time series against the null hypothesis by checking whether the discriminating statistic computed for the original time series differs significantly from the statistics computed for each of the surrogate sets. We present algorithms for generating surrogate data under various null hypotheses, and we show the results of numerical experiments on artificial data using correlation dimension, Lyapunov exponent, and forecasting error as discriminating statistics. Finally, we consider a number of experimental time more\u00bb",
            "Using surrogate data to detect nonlinearity in time series",
            "James Theiler and Bryan Galdrikian and Andr\u00e9e Longtin and Stephen Eubank and J Doyne Farmer",
            "1991",
            "OEjgtVsAAAAJ:roLk4NBRz8UC",
            263,
            "https:\/\/www.osti.gov\/biblio\/5299382",
            "2057890349715852071",
            "\/scholar?cites=2057890349715852071",
            {
                "1992":5,
                "1993":17,
                "1994":10,
                "1995":29,
                "1996":21,
                "1997":25,
                "1998":13,
                "1999":14,
                "2000":13,
                "2001":16,
                "2002":6,
                "2003":6,
                "2004":4,
                "2005":3,
                "2006":2,
                "2007":5,
                "2008":6,
                "2009":8,
                "2010":3,
                "2011":6,
                "2012":7,
                "2013":5,
                "2014":2,
                "2015":4,
                "2016":2,
                "2017":4,
                "2018":4,
                "2019":9,
                "2020":8
            }
        ],
        [
            "We study the three standard methods for reconstructing a state space from a time series; delays, derivatives, and principal components. We derive a closed-form solution to principal component analysis in the limit of small window widths. This solution explains the relationship between delays, derivatives, and principal components, it shows how the singular spectrum scales with dimension and delay time, and it explains why the eigenvectors resemble the Legendre polynomials Most importantly, the solution allows us to derive a guideline for choosing a good window width. Unlike previous suggestions, this guideline is based on first principles and simple quantities. We argue that discrete Legendre polynomials provide a quick and not-so-dirty substitute for principal component analysis, and that they are a good practical method for state space reconstruction.",
            "An analytic approach to practical state space reconstruction",
            "John F Gibson and J Doyne Farmer and Martin Casdagli and Stephen Eubank",
            "1992",
            "OEjgtVsAAAAJ:W5xh706n7nkC",
            262,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/0167278992900852",
            "16495262541035793083",
            "\/scholar?cites=16495262541035793083",
            {
                "1992":1,
                "1993":5,
                "1994":7,
                "1995":9,
                "1996":14,
                "1997":15,
                "1998":11,
                "1999":10,
                "2000":7,
                "2001":4,
                "2002":20,
                "2003":8,
                "2004":7,
                "2005":16,
                "2006":14,
                "2007":10,
                "2008":5,
                "2009":5,
                "2010":6,
                "2011":12,
                "2012":6,
                "2013":9,
                "2014":5,
                "2015":11,
                "2016":7,
                "2017":7,
                "2018":10,
                "2019":3,
                "2020":14,
                "2021":1
            }
        ],
        [
            "Background: An Ebola outbreak of unparalleled size is currently affecting several countries in West Africa, and international efforts to control the outbreak are underway. However, the efficacy of these interventions, and their likely impact on an Ebola epidemic of this size, is unknown. Forecasting and simulation of these interventions may inform public health efforts. Methods: We use existing data from Liberia and Sierra Leone to parameterize a mathematical model of Ebola and use this model to forecast the progression of the epidemic, as well as the efficacy of several interventions, including increased contact tracing, improved infection control practices, the use of a hypothetical pharmaceutical intervention to improve survival in hospitalized patients. Findings: Model forecasts until Dec. 31, 2014 show an increasingly severe epidemic with no sign of having reached a peak. Modeling results suggest that increased \u2026",
            "Modeling the impact of interventions on an epidemic of Ebola in Sierra Leone and Liberia",
            "Caitlin M Rivers and Eric T Lofgren and Madhav Marathe and Stephen Eubank and Bryan L Lewis",
            "2014",
            "OEjgtVsAAAAJ:PELIpwtuRlgC",
            251,
            "https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/pmc4325479\/",
            "15080760595865473025",
            "\/scholar?cites=15080760595865473025",
            {
                "2014":9,
                "2015":50,
                "2016":53,
                "2017":37,
                "2018":35,
                "2019":36,
                "2020":23,
                "2021":1
            }
        ],
        [
            "An Ebola outbreak of unprecedented scope emerged in West Africa in December 2013 and presently continues unabated in the countries of Guinea, Sierra Leone, and Liberia. Ebola is not new to Africa, and outbreaks have been confirmed as far back as 1976. The current West African Ebola outbreak is the largest ever recorded and differs dramatically from prior outbreaks in its duration, number of people affected, and geographic extent. The emergence of this deadly disease in West Africa invites many questions, foremost among these: why now, and why in West Africa? Here, we review the sociological, ecological, and environmental drivers that might have influenced the emergence of Ebola in this region of Africa and its spread throughout the region. Containment of the West African Ebola outbreak is the most pressing, immediate need. A comprehensive assessment of the drivers of Ebola emergence and sustained human-to-human transmission is also needed in order to prepare other countries for importation or emergence of this disease. Such assessment includes identification of country-level protocols and interagency policies for outbreak detection and rapid response, increased understanding of cultural and traditional risk factors within and between nations, delivery of culturally embedded public health education, and regional coordination and collaboration, particularly with governments and health ministries throughout Africa. Public health education is also urgently needed in countries outside of Africa in order to ensure that risk is properly understood and public concerns do not escalate unnecessarily. To prevent future outbreaks \u2026",
            "What factors might have led to the emergence of Ebola in West Africa?",
            "Kathleen A Alexander and Claire E Sanderson and Madav Marathe and Bryan L Lewis and Caitlin M Rivers and Jeffrey Shaman and John M Drake and Eric Lofgren and Virginia M Dato and Marisa C Eisenberg and Stephen Eubank",
            "2015",
            "OEjgtVsAAAAJ:hMod-77fHWUC",
            250,
            "https:\/\/journals.plos.org\/plosntds\/article?id=10.1371\/journal.pntd.0003652",
            "6627556819920686032",
            "\/scholar?cites=6627556819920686032",
            {
                "2014":1,
                "2015":32,
                "2016":58,
                "2017":47,
                "2018":41,
                "2019":28,
                "2020":37,
                "2021":4
            }
        ]
    ]
}