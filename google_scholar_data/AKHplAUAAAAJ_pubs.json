{
    "columns":[
        "abstract",
        "title",
        "author",
        "pub_year",
        "author_pub_id",
        "num_citations",
        "pub_url",
        "cites_id",
        "citedby_url",
        "cites_per_year"
    ],
    "index":[
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
    ],
    "data":[
        [
            "An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of``normal''examples with only a small percentage of``abnormal''or``interesting''examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4. 5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.",
            "SMOTE: synthetic minority over-sampling technique",
            "Nitesh V Chawla and Kevin W Bowyer and Lawrence O Hall and W Philip Kegelmeyer",
            "2002",
            "AKHplAUAAAAJ:u5HHmVD_uO8C",
            13136,
            "http:\/\/www.jair.org\/index.php\/jair\/article\/view\/10302",
            "6098173364447625309",
            "\/scholar?cites=6098173364447625309",
            {
                "2004":44,
                "2005":61,
                "2006":111,
                "2007":123,
                "2008":150,
                "2009":233,
                "2010":273,
                "2011":317,
                "2012":417,
                "2013":512,
                "2014":640,
                "2015":760,
                "2016":876,
                "2017":1167,
                "2018":1705,
                "2019":2423,
                "2020":2943,
                "2021":232
            }
        ],
        [
            "Many real world data mining applications involve learning from imbalanced data sets. Learning from data sets that contain very few instances of the minority (or interesting) class usually produces biased classifiers that have a higher predictive accuracy over the majority class(es), but poorer predictive accuracy over the minority class. SMOTE (Synthetic Minority Over-sampling TEchnique) is specifically designed for learning from imbalanced data sets. This paper presents a novel approach for learning from imbalanced data sets, based on a combination of the SMOTE algorithm and the boosting procedure. Unlike standard boosting where all misclassified examples are given equal weights, SMOTEBoost creates synthetic examples from the rare or minority class, thus indirectly changing the updating weights and compensating for skewed distributions. SMOTEBoost applied to several highly and moderately \u2026",
            "SMOTEBoost: Improving prediction of the minority class in boosting",
            "Nitesh V Chawla and Aleksandar Lazarevic and Lawrence O Hall and Kevin W Bowyer",
            "2003",
            "AKHplAUAAAAJ:zYLM7Y9cAGgC",
            1416,
            "https:\/\/link.springer.com\/chapter\/10.1007\/978-3-540-39804-2_12",
            "9861594267464036235",
            "\/scholar?cites=9861594267464036235",
            {
                "2003":5,
                "2004":11,
                "2005":8,
                "2006":12,
                "2007":15,
                "2008":32,
                "2009":44,
                "2010":41,
                "2011":57,
                "2012":85,
                "2013":103,
                "2014":104,
                "2015":101,
                "2016":114,
                "2017":138,
                "2018":139,
                "2019":192,
                "2020":182,
                "2021":16
            }
        ],
        [
            "A. Cllnical rationale Magnetic resonance imaging (MRI) systems measure spatial distributions of several distinct tissue-related parameters such as relaxation times and proton density. Analogous to LANDSAT imagery, MRI measurements are collections of features (that is, numerical characteristics) from spatial arrays that are aggregated into multidimen-sional data (from a single anatomical slice).\" Measured intensities at p different \u201cfrequencies\u201d at each spatial (pixel) location can be used as a basis for algorithmically formed tissue clusters in p-dimensional feature space, which is the collection of all possible aggregates of the measured features. Asp is increased using different tailored pulse sequences, higher-dimensional feature spaces may yield improved image segmentation when compared to visual interpretation or gray-scale segmentation of single",
            "Review of MR image segmentation techniques using pattern recognition",
            "James C Bezdek and LO Hall and L_P Clarke",
            "1993",
            "AKHplAUAAAAJ:u-x6o8ySG0sC",
            1362,
            "https:\/\/aapm.onlinelibrary.wiley.com\/doi\/abs\/10.1118\/1.597000",
            "5460300214102710967",
            "\/scholar?cites=5460300214102710967",
            {
                "1994":15,
                "1995":27,
                "1996":24,
                "1997":35,
                "1998":38,
                "1999":49,
                "2000":57,
                "2001":38,
                "2002":45,
                "2003":41,
                "2004":49,
                "2005":50,
                "2006":60,
                "2007":56,
                "2008":58,
                "2009":61,
                "2010":77,
                "2011":60,
                "2012":72,
                "2013":78,
                "2014":72,
                "2015":59,
                "2016":68,
                "2017":53,
                "2018":40,
                "2019":35,
                "2020":19,
                "2021":6
            }
        ],
        [
            "\u201cRadiomics\u201d refers to the extraction and analysis of large amounts of advanced quantitative imaging features with high throughput from medical images obtained with computed tomography, positron emission tomography or magnetic resonance imaging. Importantly, these data are designed to be extracted from standard-of-care images, leading to a very large potential subject pool. Radiomics data are in a mineable form that can be used to build descriptive and predictive models relating image features to phenotypes or gene\u2013protein signatures. The core hypothesis of radiomics is that these models, which can include biological or medical data, can provide valuable diagnostic, prognostic or predictive information. The radiomics enterprise can be divided into distinct processes, each with its own challenges that need to be overcome: (a) image acquisition and reconstruction, (b) image segmentation and rendering, (c \u2026",
            "Radiomics: the process and the challenges",
            "Virendra Kumar and Yuhua Gu and Satrajit Basu and Anders Berglund and Steven A Eschrich and Matthew B Schabath and Kenneth Forster and Hugo JWL Aerts and Andre Dekker and David Fenstermacher and Dmitry B Goldgof and Lawrence O Hall and Philippe Lambin and Yoganand Balagurunathan and Robert A Gatenby and Robert J Gillies",
            "2012",
            "AKHplAUAAAAJ:0izLItjtcgwC",
            1115,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0730725X12002202",
            "16543319338193910782",
            "\/scholar?cites=16543319338193910782",
            {
                "2013":7,
                "2014":17,
                "2015":44,
                "2016":97,
                "2017":145,
                "2018":213,
                "2019":256,
                "2020":309,
                "2021":23
            }
        ],
        [
            "The current literature on MRI segmentation methods is reviewed. Particular emphasis is placed on the relative merits of single image versus multispectral segmentation, and supervised versus unsupervised segmentation methods. Image pre-processing and registration are discussed, as well as methods of validation. The application of MRI segmentation for tumor volume measurements during the course of therapy is presented here as an example, illustrating problems associated with inter- and intra-observer variations inherent to supervised methods.",
            "MRI segmentation: methods and applications",
            "LP Clarke and RP Velthuizen and MA Camacho and JJ Heine and M Vaidyanathan and LO Hall and RW Thatcher and ML Silbiger",
            "1995",
            "AKHplAUAAAAJ:d1gkVwhDpl0C",
            989,
            "https:\/\/www.sciencedirect.com\/science\/article\/pii\/0730725X9400124L",
            "9066637671563266715",
            "\/scholar?cites=9066637671563266715",
            {
                "1995":8,
                "1996":22,
                "1997":30,
                "1998":42,
                "1999":44,
                "2000":34,
                "2001":38,
                "2002":42,
                "2003":41,
                "2004":42,
                "2005":41,
                "2006":44,
                "2007":36,
                "2008":46,
                "2009":32,
                "2010":44,
                "2011":53,
                "2012":53,
                "2013":51,
                "2014":28,
                "2015":39,
                "2016":47,
                "2017":43,
                "2018":34,
                "2019":21,
                "2020":22,
                "2021":2
            }
        ],
        [
            "Magnetic resonance (MR) brain section images are segmented and then synthetically colored to give visual representations of the original data with three approaches: the literal and approximate fuzzy c-means unsupervised clustering algorithms, and a supervised computational neural network. Initial clinical results are presented on normal volunteers and selected patients with brain tumors surrounded by edema. Supervised and unsupervised segmentation techniques provide broadly similar results. Unsupervised fuzzy algorithms were visually observed to show better segmentation when compared with raw image data for volunteer studies. For a more complex segmentation problem with tumor\/edema or cerebrospinal fluid boundary, where the tissues have similar MR relaxation behavior, inconsistency in rating among experts was observed, with fuzz-c-means approaches being slightly preferred over feedforward \u2026",
            "A comparison of neural network and fuzzy clustering techniques in segmenting magnetic resonance images of the brain",
            "Lawrence O Hall and Amine M Bensaid and Laurence P Clarke and Robert P Velthuizen and Martin S Silbiger and James C Bezdek",
            "1992",
            "AKHplAUAAAAJ:2osOgNQ5qMEC",
            746,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/159057\/",
            "14157446391589146664",
            "\/scholar?cites=14157446391589146664",
            {
                "1993":18,
                "1994":15,
                "1995":25,
                "1996":34,
                "1997":28,
                "1998":41,
                "1999":21,
                "2000":24,
                "2001":16,
                "2002":26,
                "2003":25,
                "2004":19,
                "2005":30,
                "2006":23,
                "2007":24,
                "2008":28,
                "2009":21,
                "2010":34,
                "2011":26,
                "2012":30,
                "2013":45,
                "2014":40,
                "2015":23,
                "2016":31,
                "2017":28,
                "2018":31,
                "2019":20,
                "2020":13
            }
        ],
        [
            "A system that automatically segments and labels glioblastoma-multiforme tumors in magnetic resonance images (MRIs) of the human brain is presented. The MRIs consist of T1-weighted, proton density, and T2-weighted feature images and are processed by a system which integrates knowledge-based (KB) techniques with multispectral analysis. Initial segmentation is performed by an unsupervised clustering algorithm. The segmented image, along with cluster centers for each class are provided to a rule-based expert system which extracts the intracranial region. Multispectral histogram analysis separates suspected tumor from the rest of the intracranial region, with region analysis used in performing the final tumor labeling. This system has been trained on three volume data sets and tested on thirteen unseen volume data sets acquired from a single MRI system. The KB tumor segmentation was compared with \u2026",
            "Automatic tumor segmentation using knowledge-based techniques",
            "Matthew C Clark and Lawrence O Hall and Dmitry B Goldgof and Robert Velthuizen and F Reed Murtagh and Martin S.  Silbiger",
            "1998",
            "AKHplAUAAAAJ:UeHWp8X0CEIC",
            642,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/700731\/",
            "14773356197352743978",
            "\/scholar?cites=14773356197352743978",
            {
                "1998":4,
                "1999":13,
                "2000":17,
                "2001":11,
                "2002":15,
                "2003":15,
                "2004":28,
                "2005":18,
                "2006":19,
                "2007":19,
                "2008":20,
                "2009":28,
                "2010":39,
                "2011":45,
                "2012":42,
                "2013":46,
                "2014":40,
                "2015":59,
                "2016":35,
                "2017":37,
                "2018":32,
                "2019":26,
                "2020":20,
                "2021":4
            }
        ],
        [
            "Describes a genetically guided approach to optimizing the hard (J\/sub 1\/) and fuzzy (J\/sub m\/) c-means functionals used in cluster analysis. Our experiments show that a genetic algorithm (GA) can ameliorate the difficulty of choosing an initialization for the c-means clustering algorithms. Experiments use six data sets, including the Iris data, magnetic resonance, and color images. The genetic algorithm approach is generally able to find the lowest known J\/sub m\/ value or a J\/sub m\/ associated with a partition very similar to that associated with the lowest J\/sub m\/ value. On data sets with several local extrema, the GA approach always avoids the less desirable solutions. Degenerate partitions are always avoided by the GA approach, which provides an effective method for optimizing clustering models whose objective function can be represented in terms of cluster centers. A series random initializations of fuzzy\/hard c \u2026",
            "Clustering with a genetically optimized approach",
            "Lawrence O Hall and Ibrahim Burak Ozyurt and James C Bezdek",
            "1999",
            "AKHplAUAAAAJ:9yKSN-GCB0IC",
            578,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/771164\/",
            "3556878916808085180",
            "\/scholar?cites=3556878916808085180",
            {
                "1999":2,
                "2000":8,
                "2001":16,
                "2002":21,
                "2003":23,
                "2004":37,
                "2005":45,
                "2006":53,
                "2007":47,
                "2008":49,
                "2009":37,
                "2010":40,
                "2011":34,
                "2012":41,
                "2013":25,
                "2014":25,
                "2015":15,
                "2016":14,
                "2017":11,
                "2018":9,
                "2019":8,
                "2020":6
            }
        ],
        [
            "When clustering algorithms are applied to image segmentation, the goal is to solve a classification problem. However, these algorithms do not directly optimize classification duality. As a result, they are susceptible to two problems: 1) the criterion they optimize may not be a good estimator of \"true\" classification quality, and 2) they often admit many (suboptimal) solutions. This paper introduces an algorithm that uses cluster validity to mitigate problems 1 and 2. The validity-guided (re)clustering (VGC) algorithm uses cluster-validity information to guide a fuzzy (re)clustering process toward better solutions. It starts with a partition generated by a soft or fuzzy clustering algorithm. Then it iteratively alters the partition by applying (novel) split-and-merge operations to the clusters. Partition modifications that result in improved partition validity are retained. VGC is tested on both synthetic and real-world data. For magnetic \u2026",
            "Validity-guided (re) clustering with applications to image segmentation",
            "Amine M Bensaid and Lawrence O Hall and James C Bezdek and Laurence P Clarke and Martin L Silbiger and John A Arrington and Reed F Murtagh",
            "1996",
            "AKHplAUAAAAJ:qjMakFHDy7sC",
            516,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/493905\/",
            "17382307488005135240",
            "\/scholar?cites=17382307488005135240",
            {
                "1996":2,
                "1997":4,
                "1998":7,
                "1999":12,
                "2000":8,
                "2001":9,
                "2002":7,
                "2003":18,
                "2004":15,
                "2005":20,
                "2006":18,
                "2007":33,
                "2008":40,
                "2009":31,
                "2010":17,
                "2011":37,
                "2012":32,
                "2013":31,
                "2014":42,
                "2015":24,
                "2016":30,
                "2017":22,
                "2018":25,
                "2019":12,
                "2020":16,
                "2021":1
            }
        ],
        [
            "We experimentally evaluate bagging and seven other randomization-based approaches to creating an ensemble of decision tree classifiers. Statistical tests were performed on experimental results from 57 publicly available data sets. When cross-validation comparisons were tested for statistical significance, the best method was statistically more accurate than bagging on only eight of the 57 data sets. Alternatively, examining the average ranks of the algorithms across the group of data sets, we find that boosting, random forests, and randomized trees are statistically significantly better than bagging. Because our results suggest that using an appropriate ensemble size is important, we introduce an algorithm that decides when a sufficient number of classifiers has been created for an ensemble. Our algorithm uses the out-of-bag error estimate, and is shown to result in an accurate ensemble for those methods that \u2026",
            "A comparison of decision tree ensemble creation techniques",
            "Robert E Banfield and Lawrence O Hall and Kevin W Bowyer and W Philip Kegelmeyer",
            "2006",
            "AKHplAUAAAAJ:YsMSGLbcyi4C",
            475,
            "https:\/\/ieeexplore.ieee.org\/abstract\/document\/4016560\/",
            "12541159607369090930",
            "\/scholar?cites=12541159607369090930",
            {
                "2007":13,
                "2008":22,
                "2009":27,
                "2010":30,
                "2011":28,
                "2012":43,
                "2013":46,
                "2014":30,
                "2015":39,
                "2016":33,
                "2017":41,
                "2018":35,
                "2019":30,
                "2020":45,
                "2021":5
            }
        ]
    ]
}