{
    "columns":[
        "id",
        "google_scholar_id",
        "titles",
        "abstracts",
        "interests"
    ],
    "index":[
        0
    ],
    "data":[
        [
            "WGS49GYU",
            "PuvWhu4AAAAJ",
            [
                "Transfer and\/or Breakup Modes in the  Reaction near the Coulomb Barrier",
                "3-D localization of virtual sound sources: Effects of visual environment, pointing method, and training",
                "Studies on bilateral cochlear implants at the University of Wisconsin\u2019s Binaural Hearing and Speech Laboratory",
                "Effect of mismatched place-of-stimulation on binaural fusion and lateralization in bilateral cochlear-implant users",
                "Effect of mismatched place-of-stimulation on the salience of binaural cues in conditions that simulate bilateral cochlear-implant listening",
                "Effects of interaural pitch-matching and auditory image centering on binaural sensitivity in cochlear-implant users",
                "Having two ears facilitates the perceptual separation of concurrent talkers for bilateral and single-sided deaf cochlear implantees",
                "Two-Dimensional Sound Localization in Cochlear Implantees",
                "Interaural fluctuations and the detection of interaural incoherence: Bandwidth effects",
                "Interaural fluctuations and the detection of interaural incoherence. III. Narrowband experiments and binaural models"
            ],
            [
                "Reaction products from the interaction of 6 He with 209 Bi have been measured at energies near the Coulomb barrier. A 4 He group of remarkable intensity, which dominates the total reaction cross section, has been observed. The angular distribution of the group suggests that it results primarily from a direct nuclear process. It is likely that this transfer and\/or breakup channel is the doorway state that accounts for the previously observed large sub-barrier fusion enhancement in this system.",
                "The ability to localize sound sources in three-dimensional space was tested in humans. In Experiment 1, naive subjects listened to noises filtered with subject-specific head-related transfer functions. The tested conditions included the pointing method (head or manual pointing) and the visual environment (VE; darkness or virtual VE). The localization performance was not significantly different between the pointing methods. The virtual VE significantly improved the horizontal precision and reduced the number of front-back confusions. These results show the benefit of using a virtual VE in sound localization tasks. In Experiment 2, subjects were provided with sound localization training. Over the course of training, the performance improved for all subjects, with the largest improvements occurring during the first 400 trials. The improvements beyond the first 400 trials were smaller. After the training, there was still \u2026",
                "This report highlights research projects relevant to binaural and spatial hearing in adults and children. In the past decade we have made progress in understanding the impact of bilateral cochlear implants (BiCIs) on performance in adults and children. However, BiCI users typically do not perform as well as normal hearing (NH) listeners. In this article we describe the benefits from BiCIs compared with a single cochlear implant (CI), focusing on measures of spatial hearing and speech understanding in noise. We highlight the fact that in BiCI listening the devices in the two ears are not coordinated; thus binaural spatial cues that are available to NH listeners are not available to BiCI users. Through the use of research processors that carefully control the stimulus delivered to each electrode in each ear, we are able to preserve binaural cues and deliver them with fidelity to BiCI users. Results from those studies are \u2026",
                "Bilateral cochlear implants (CIs) have provided some success in improving spatial hearing abilities to patients, but with large variability in performance. One reason for the variability is that there may be a mismatch in the place-of-stimulation arising from electrode arrays being inserted at different depths in each cochlea. Goupell et al. [(2013b). J. Acoust. Soc. Am. 133(4), 2272\u20132287] showed that increasing interaural mismatch led to non-fused auditory images and poor lateralization of interaural time differences in normal hearing subjects listening to a vocoder. However, a greater bandwidth of activation helped mitigate these effects. In the present study, the same experiments were conducted in post-lingually deafened bilateral CI users with deliberate and controlled interaural mismatch of single electrode pairs. Results show that lateralization was still possible with up to 3\u2009mm of interaural mismatch, even when off \u2026",
                "Although bilateral cochlear implantation has the potential to improve sound localization and speech understanding in noise, obstacles exist in presenting maximally useful binaural information to bilateral cochlear-implant (CI) users. One obstacle is that electrode arrays may differ in cochlear position by several millimeters, thereby stimulating different neural populations. Effects of interaural frequency mismatch on binaural processing were studied in normal-hearing (NH) listeners using band-limited pulse trains, thereby avoiding confounding factors that may occur in CI users. In experiment 1, binaural image fusion was measured to capture perceptual number, location, and compactness. Subjects heard a single, compact image on 73% of the trials. In experiment 2, intracranial image location was measured for different interaural time differences (ITDs) and interaural level differences (ILDs). For larger mismatch \u2026",
                "ObjectivesIn bilateral cochlear implant users, electrodes mapped to the same frequency range in each ear may stimulate different places in each cochlea due to an insertion depth difference of electrode arrays. This interaural place of stimulation mismatch can lead to problems with auditory image fusion and sensitivity to binaural cues, which may explain large localization errors seen in many patients. Previous work has shown that interaural place of stimulation mismatch can lead to off-centered auditory images being perceived even though interaural time and level differences (ITD and ILD, respectively) were zero. Large interaural mismatches reduced the ability to use ITDs for auditory image lateralization. In contrast, lateralization with ILDs was still possible but the mapping of ILDs to spatial locations was distorted. This study extends the previous work by systematically investigating the effect of interaural place of \u2026",
                "ObjectivesListening to speech with multiple competing talkers requires the perceptual separation of the target voice from the interfering background. Normal-hearing (NH) listeners are able to take advantage of perceived differences in the spatial locations of competing sound sources to facilitate this process. Previous research suggests that bilateral (BI) cochlear-implant (CI) listeners cannot do so, and it is unknown whether single-sided deaf CI users (SSD-CI; one acoustic and one CI ear) have this ability. This study investigated whether providing a second ear via cochlear implantation can facilitate the perceptual separation of targets and interferers in a listening situation involving multiple competing talkers.DesignBI-CI and SSD-CI listeners were required to identify speech from a target talker mixed with one or two interfering talkers. In the baseline monaural condition, the target speech and the interferers were \u2026",
                "Cochlear implants (CIs) have become an effective tool in the treatment of profound hearing impairment and deafness. Compared with monaural stimulation, bilateral stimulation provides improvements in speech perception in noise (eg, Schleich, Nopp & D'Haese, 2004) and horizontal-plane sound localization (eg, van Hoesel & Tyler, 2003; Nopp, Schleich & D'Haese, 2004). The auditory system uses binaural cues to localize sounds in the horizontal plane (eg, Macpherson & Middlebrooks, 2002), and these cues, in the form of interaural level differences and interaural time differences, can be used in electric stimulation to some extent (eg, Laback, Pok, Baumgartner, Deutsch & Schmid, 2004; Grantham, Ashmead, Ricketts, Haynes & Labadie, 2008). In contrast, vertical-plane sound localization and front-back discrimination rely on the spectral coloration or timbre of the incoming sounds (Carlile & Pralong, 1994 \u2026",
                "One-hundred left-right noise-pairs were generated, all with a fixed value of long-term interaural coherence, 0.9922. The noises had a center frequency of 500Hz, a bandwidth of 14Hz, and a duration of 500ms. Listeners were required to discriminate between these slightly incoherent noises and diotic noises, with a coherence of 1.0. It was found that the value of interaural coherence itself was an inadequate predictor of discrimination. Instead, incoherence was much more readily detected for those noise-pairs with the largest fluctuations in interaural phase or level differences (as measured by the standard deviations). One-hundred noise-pairs with the same value of coherence, 0.9922, and geometric mean frequency of 500Hz were also generated for bandwidths of 108 and 2394Hz. It was found that for increasing bandwidth, fluctuations in interaural differences varied less between different noise-pairs and that \u2026",
                "In the first two articles of this series, reproducible noises with a fixed value of interaural coherence (0.992) were used to study the human ability to detect interaural incoherence. It was found that incoherence detection is strongly correlated with fluctuations in interaural differences, especially for narrow noise bandwidths, but it remained unclear what function of the fluctuations best agrees with detection data. In the present article, ten different binaural models were tested against detection data for 14- and 108-Hz bandwidths. These models included different types of binaural processing: independent-interaural-phase-difference\/interaural-level-difference, lateral-position, and short-term cross-correlation. Several preprocessing transformations of the interaural differences were incorporated: compression of binaural cues, temporal averaging, and envelope weighting. For the 14-Hz bandwidth data, the most successful \u2026"
            ],
            [
                [
                    "Psychoacoustics"
                ]
            ]
        ]
    ]
}