{
    "columns":[
        "id",
        "google_scholar_id",
        "titles",
        "abstracts",
        "interests"
    ],
    "index":[
        0
    ],
    "data":[
        [
            "TVUNE44S",
            "Xd_w2fIAAAAJ",
            [
                "Inferring decoding strategies from choice probabilities in the presence of correlated variability",
                "Perceptual decision-making as probabilistic inference by neural sampling",
                "A dynamical model of the inner Galaxy",
                "Feedback determines the structure of correlated variability in primary visual cortex",
                "Adaptation to natural binocular disparities in primate V1 explained by a generalized energy model",
                "Simple three-integral scale-free galaxy models",
                "A neural basis for the spatial suppression of visual motion perception",
                "Suppressive mechanisms in monkey V1 help to solve the stereo correspondence problem",
                "A modality-specific feedforward component of choice-related activity in MT",
                "Slowness and sparseness have diverging effects on complex cell learning"
            ],
            [
                "The activity of cortical neurons in sensory areas covaries with perceptual decisions, a relationship that is often quantified by choice probabilities. Although choice probabilities have been measured extensively, their interpretation has remained fraught with difficulty. We derive the mathematical relationship between choice probabilities, read-out weights and correlated variability in the standard neural decision-making model. Our solution allowed us to prove and generalize earlier observations on the basis of numerical simulations and to derive new predictions. Notably, our results indicate how the read-out weight profile, or decoding strategy, can be inferred from experimentally measurable quantities. Furthermore, we developed a test to decide whether the decoding weights of individual neurons are optimal for the task, even without knowing the underlying correlations. We confirmed the practicality of our approach \u2026",
                "We address two main challenges facing systems neuroscience today: understanding the nature and function of cortical feedback between sensory areas and of correlated variability. Starting from the old idea of perception as probabilistic inference, we show how to use knowledge of the psychophysical task to make testable predictions for the influence of feedback signals on early sensory representations. Applying our framework to a two-alternative forced choice task paradigm, we can explain multiple empirical findings that have been hard to account for by the traditional feedforward model of sensory processing, including the task dependence of neural response correlations and the diverging time courses of choice probabilities and psychophysical kernels. Our model makes new predictions and characterizes a component of correlated variability that represents task-related information rather than performance \u2026",
                "An extension of Schwarzschild's galaxy-building technique is presented that enables one to build Schwarzschild models with known distribution functions (DFs). The new extension makes it possible to combine a DF that depends only on classical integrals with orbits that respect non-classical integrals. With such a combination, Schwarzschild's orbits are used only to represent the difference between the true galaxy DF and an approximating classical DF.The new method is used to construct a dynamical model of the inner Galaxy. The model is based on an orbit library that contains 22 168 regular orbits. The model aims to reproduce the three-dimensional mass density of Binney, Gerhard & Spergel, which was obtained through deprojection of the COBE surface photometry, and to reproduce the observed kinematics in three windows \u2014 namely Baade's Window with (\u2113,b) = (1\u00b0,\u22124\u00b0) and two off-axis fields at \u2026",
                "The variable responses of sensory neurons tend to be weakly correlated (spike-count correlation, r sc). This is widely thought to reflect noise in shared afferents, in which case r sc can limit the reliability of sensory coding. However, it could also be due to feedback from higher-order brain regions. Currently, the relative contributions of these sources are unknown. We addressed this by recording from populations of V1 neurons in macaques performing different discrimination tasks involving the same visual input. We found that the structure of r sc (the way r sc varied with neuronal stimulus preference) changed systematically with task instruction. Therefore, even at the earliest stage in the cortical visual hierarchy, r sc structure during task performance primarily reflects feedback dynamics. Consequently, previous proposals for how r sc constrains sensory processing need not apply. Furthermore, we show that \u2026",
                "Sensory processing in the brain is thought to have evolved to encode naturally occurring stimuli efficiently. We report an adaptation in binocular cortical neurons that reflects the tight constraints imposed by the geometry of 3D vision. We show that the widely used binocular energy model predicts that neurons dedicate part of their dynamic range to impossible combinations of left and right images. Approximately 42% of the neurons we record from V1 of awake monkeys behave in this way (a powerful confirmation of the model), while about 58% deviate from the model in a manner that concentrates more of their dynamic range on stimuli that obey the constraints of binocular geometry. We propose a simple extension of the energy model, using multiple subunits, that explains the adaptation we observe, as well as other properties of binocular neurons that have been hard to account for, such as the response to \u2026",
                "The Jeans equations give the second moments or stresses required to support a stellar population against a gravity field. A general solution of the Jeans equations for arbitrary axisymmetric scale-free densities in flattened scale-free potentials is given. A two-parameter subset of the solution for the second moments for the self-consistent density of the power-law models, which have exactly spheroidal equipotentials, is examined in detail. In the spherical limit, the potential of these models reduces to that of the singular power-law spheres. We build the physical three-integral distribution functions that correspond to the flattened stellar components.Next, we attack the problem of finding distribution functions associated with the Jeans solutions in flattened scale-free potentials. The third or partial integral introduced by de Zeeuw, Evans & Schwarzschild for Binney's model is generalized to thin and near-thin \u2026",
                "In theory, sensory perception should be more accurate when more neurons contribute to the representation of a stimulus. However, psychophysical experiments that use larger stimuli to activate larger pools of neurons sometimes report impoverished perceptual performance. To determine the neural mechanisms underlying these paradoxical findings, we trained monkeys to discriminate the direction of motion of visual stimuli that varied in size across trials, while simultaneously recording from populations of motion-sensitive neurons in cortical area MT. We used the resulting data to constrain a computational model that explained the behavioral data as an interaction of three main mechanisms: noise correlations, which prevented stimulus information from growing with stimulus size; neural surround suppression, which decreased sensitivity for large stimuli; and a read-out strategy that emphasized neurons with receptive fields near the stimulus center. These results suggest that paradoxical percepts reflect tradeoffs between sensitivity and noise in neuronal populations.DOI: http:\/\/dx.doi.org\/10.7554\/eLife.16167.001",
                "Neurons encode the depth in stereoscopic images by combining the signals from the receptive fields in the two eyes. Local variations in single images can activate neurons that do not signal the correct disparity (false matches), giving rise to the stereo correspondence problem. We used binocular white-noise stimuli to decompose the responses of monkey primary visual cortex V1 neurons into the elements of a linear\u2013nonlinear model (via spike-triggered covariance analysis). In our population of disparity-selective neurons, we find both excitatory and suppressive elements in many of the neurons. Their binocular receptive fields were aligned in a specific push\u2013pull manner for disparity. We demonstrate that this arrangement reduces the responses to false matches but preserves the responses to true matches. The responses of the cells to the noise stimuli were well explained by a linear summation of the elements \u2026",
                "The activity of individual sensory neurons can be predictive of an animal\u2019s choices. These decision signals arise from network properties dependent on feedforward and feedback inputs; however, the relative contributions of these inputs are poorly understood. We determined the role of feedforward pathways to decision signals in MT by recording neuronal activity while monkeys performed motion and depth tasks. During each session, we reversibly inactivated V2 and V3, which provide feedforward input to MT that conveys more information about depth than motion. We thus monitored the choice-related activity of the same neuron both before and during V2\/V3 inactivation. During inactivation, MT neurons became less predictive of decisions for the depth task but not the motion task, indicating that a feedforward pathway that gives rise to tuning preferences also contributes to decision signals. We show that our data \u2026",
                "Following earlier studies which showed that a sparse coding principle may explain the receptive field properties of complex cells in primary visual cortex, it has been concluded that the same properties may be equally derived from a slowness principle. In contrast to this claim, we here show that slowness and sparsity drive the representations towards substantially different receptive field properties. To do so, we present complete sets of basis functions learned with slow subspace analysis (SSA) in case of natural movies as well as translations, rotations, and scalings of natural images. SSA directly parallels independent subspace analysis (ISA) with the only difference that SSA maximizes slowness instead of sparsity. We find a large discrepancy between the filter shapes learned with SSA and ISA. We argue that SSA can be understood as a generalization of the Fourier transform where the power spectrum corresponds to the maximally slow subspace energies in SSA. Finally, we investigate the trade-off between slowness and sparseness when combined in one objective function."
            ],
            [
                [
                    "Sensory processing",
                    "probabilistic inference",
                    "neural sampling",
                    "binocular vision"
                ]
            ]
        ]
    ]
}