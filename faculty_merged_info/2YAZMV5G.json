{
    "columns":[
        "id",
        "google_scholar_id",
        "titles",
        "abstracts",
        "interests",
        "personal_page_content"
    ],
    "index":[
        0
    ],
    "data":[
        [
            "2YAZMV5G",
            "WcW-GYsAAAAJ",
            [
                "Web Database Applications with PHP and MySQL: Building Effective Database-Driven Web Sites",
                "Compression of inverted indexes for fast query evaluation",
                "Compressing integers for fast file access",
                "Stemming Indonesian: A confix-stripping approach",
                "Burst tries: a fast, efficient data structure for string keys",
                "Fast generation of result snippets in web search",
                "Query expansion using associated queries",
                "Indexing and retrieval for genomic databases",
                "Fast phrase querying with combined indexes",
                "Improved gapped alignment in BLAST"
            ],
            [
                "There are many reasons for serving up dynamic content from a web site: to offer an online shopping site, create customized information pages for users, or just manage a large volume of content through a database. Anyone with a modest knowledge of HTML and web site management can learn to create dynamic content through the PHP programming language and the MySQL database. This book gives you the background and tools to do the job safely and reliably. Web Database Applications with PHP and MySQL, Second Edition thoroughly reflects the needs of real-world applications. It goes into detail on such practical issues as validating input (do you know what a proper credit card number looks like?), logging in users, and using templatesto give your dynamic web pages a standard look. But this book goes even further. It shows how JavaScript and PHP can be used in tandem to make a user's experience faster and more pleasant. It shows the correct way to handle errors in user input so that a site looks professional. It introduces the vast collection of powerful tools available in the PEAR repository and shows how to use some of the most popular tools. Even while it serves as an introduction to new programmers, the book does not omit critical tasks that web sites require. For instance, every site that allows updates must handle the possibility of multiple users accessing data at the same time. This book explains how to solve the problem in detail with locking. Through a sophisticated sample application--Hugh and Dave's Wine Store--all the important techniques of dynamic content are introduced. Good design is emphasized, such as dividing \u2026",
                "Compression reduces both the size of indexes and the time needed to evaluate queries. In this paper, we revisit the compression of inverted lists of document postings that store the position and frequency of indexed terms, considering two approaches to improving retrieval efficiency: better implementation and better choice of integer compression schemes. First, we propose several simple optimisations to well-known integer compression schemes, and show experimentally that these lead to significant reductions in time. Second, we explore the impact of choice of compression scheme on retrieval efficiency. In experiments on large collections of data, we show two surprising results: use of simple byte-aligned codes halves the query evaluation time compared to the most compact Golomb-Rice bitwise compression schemes; and, even when an index fits entirely in memory, byte-aligned codes result in faster query \u2026",
                "Fast access to files of integers is crucial for the efficient resolution of queries to databases. Integers are the basis of indexes used to resolve queries, for example, in large internet search systems, and numeric data forms a large part of most databases. Disk access costs can be reduced by compression, if the cost of retrieving a compressed representation from disk and the CPU cost of decoding such a representation is less than that of retrieving uncompressed data. In this paper we show experimentally that, for large or small collections, storing integers in a compressed format reduces the time required for either sequential stream access or random access. We compare different approaches to compressing integers, including the Elias gamma and delta codes, Golomb coding, and a variable-byte integer scheme. As a conclusion, we recommend that, for fast access to integers, files be stored compressed.",
                "Stemming words to (usually) remove suffixes has applications in text search, machine translation, document summarization, and text classification. For example, English stemming reduces the words \"computer,\" \"computing,\" \"computation,\" and \"computability\" to their common morphological root, \"comput-.\" In text search, this permits a search for \"computers\" to find documents containing all words with the stem \"comput-.\" In the Indonesian language, stemming is of crucial importance: words have prefixes, suffixes, infixes, and confixes that make matching related words difficult.This work surveys existing techniques for stemming Indonesian words to their morphological roots, presents our novel and highly accurate CS algorithm, and explores the effectiveness of stemming in the context of general-purpose text information retrieval through ad hoc queries.",
                "Many applications depend on efficient management of large sets of distinct strings in memory. For example, during index construction for text databases a record is held for each distinct word in the text, containing the word itself and information such as counters. We propose a new data structure, the burst trie, that has significant advantages over existing options for such applications: it uses about the same memory as a binary search tree; it is as fast as a trie; and, while not as fast as a hash table, a burst trie maintains the strings in sorted or near-sorted order. In this paper we describe burst tries and explore the parameters that govern their performance. We experimentally determine good choices of parameters, and compare burst tries to other structures used for the same task, with a variety of data sets. These experiments show that the burst trie is particularly effective for the skewed frequency distributions common in \u2026",
                "The presentation of query biased document snippets as part of results pages presented by search engines has become an expectation of search engine users. In this paper we explore the algorithms and data structures required as part of a search engine to allow efficient generation of query biased snippets. We begin by proposing and analysing a document compression method that reduces snippet generation time by 58% over a baseline using the zlib compression library. These experiments reveal that finding documents on secondary storage dominates the total cost of generating snippets, and so caching documents in RAM is essential for a fast snippet generation process. Using simulation, we examine snippet generation performance for different size RAM caches. Finally we propose and analyse document reordering and compaction, revealing a scheme that increases the number of document cache hits with \u2026",
                "Hundreds of millions of users each day use web search engines to meet their information needs. Advances in web search effectiveness are therefore perhaps the most significant public outcomes of IR research. Query expansion is one such method for improving the effectiveness of ranked retrieval by adding additional terms to a query. In previous approaches to query expansion, the additional terms are selected from highly ranked documents returned from an initial retrieval run. We propose a new method of obtaining expansion terms, based on selecting terms from past user queries that are associated with documents in the collection. Our scheme is effective for query expansion for web retrieval: our results show relative improvements over unexpanded full text retrieval of 26%--29%, and 18%--20% over an optimised, conventional expansion approach.",
                "Genomic sequence databases are widely used by molecular biologists for homology searching. Amino acid and nucleotide databases are increasing in size exponentially, and mean sequence lengths are also increasing. In searching such databases, it is desirable to use heuristics to perform computationally intensive local alignments on selected sequences and to reduce the costs of the alignments that are attempted. We present an index-based approach for both selecting sequences that display broad similarity to a query and for fast local alignment. We show experimentally that the indexed approach results in significant savings in computationally intensive local alignments and that index-based searching is as accurate as existing exhaustive search schemes.",
                "Search engines need to evaluate queries extremely fast, a challenging task given the quantities of data being indexed. A significant proportion of the queries posed to search engines involve phrases. In this article we consider how phrase queries can be efficiently supported with low disk overheads. Our previous research has shown that phrase queries can be rapidly evaluated using nextword indexes, but these indexes are twice as large as conventional inverted files. Alternatively, special-purpose phrase indexes can be used, but it is not feasible to index all phrases. We propose combinations of nextword indexes and phrase indexes with inverted files as a solution to this problem. Our experiments show that combined use of a partial nextword, partial phrase, and conventional inverted index allows evaluation of phrase queries in a quarter the time required to evaluate such queries with an inverted file alone; the \u2026",
                "Homology search is a key tool for understanding the role, structure, and biochemical function of genomic sequences. The most popular technique for rapid homology search is BLAST, which has been in widespread use within universities, research centers, and commercial enterprises since the early 1990s. We propose a new step in the BLAST algorithm to reduce the computational cost of searching with negligible effect on accuracy. This new step - semigapped alignment - compromises between the efficiency of ungapped alignment and the accuracy of gapped alignment, allowing BLAST to accurately filter sequences with lower computational cost. In addition, we propose a heuristic - restricted insertion alignment - that avoids unlikely evolutionary paths with the aim of reducing gapped alignment cost with negligible effect on accuracy. Together, after including an optimization of the local alignment recursion, our \u2026"
            ],
            [
                [

                ]
            ],
            [
                "Hugh Williams Mary Amanda Wood Professor of Physics Experimental Particle Physics, Collider Physics DRL 4N16A Professional Appointments: 2009 \u2013 Mary Amanda Wood Professor of Physics and Astronomy, University of Pennsylvania 1982-2009 Professor, Department of Physics and Astronomy, University of Pennsylvania 1981 Scientific Associate, CERN 1978-1982 Associate Professor, Department of Physics and Astronomy, University of Pennsylvania 1978 Visiting Scientist, KEK National Laboratory 1974-1978 Assistant Professor, Department of Physics and Astronomy, University of Pennsylvania 1973-1974 Associate Physicist, Brookhaven National Laboratory 1971-1973 Postdoctoral Fellow, Brookhaven National Laboratory 1966 B.S. Physics Haverford College 1972 Ph.D. Physics Stanford University My research focuses on studies of elementary particles with the goal of understanding Nature at the most elemental level. This includes both identifying the most \u201cfundamental particles\u201d and studying their interactions. Earlier in my career, I studied the interactions of neutrinos in several different experiments at Brookhaven National Laboratory; highlights included the first observation of a charmed baryon, the first quantitative measurements of the elastic scattering of neutrinos from protons, and refined measurements of the elastic scattering of neutrinos from electrons. These results played an important part in establishing the \u201cStandard Model\u201d of elementary particles, the current, highly successful theory which explains almost all known particle interactions. Subsequently, I became involved in helping to build the CDF detector at Fermilab in Batavia, Illinois, and have participated over nearly twenty years in a wide range of measurements. Highlights of this research included discovery of the top quark and measurements of its mass, as well as early searches \u00a0for a new class of \u201cSupersymmetric Particles\u201d which many physicists expect to exist, but which have not yet been observed. Beginning in 1993, I became involved in the ATLAS experiment at the Large Hadron Collider with a focus on designing and delivering the on-detector electronics for the Transition Radiation Tracker, and critical element of the ATLAS tracking system which also provides electron identification. With a team of instrumentation specialists, graduate students and postdoctoral fellows, the Penn ATLAS group delivered all of the on-detector electronics for the TRT, provided the corresponding data acquisition system and also played a major role in commissioning the off-detector electronics. A series of graduate students and postdoctoral fellows from Penn have taken nearly full responsibility for the operation of the TRT data acquisition and electronics. My physic interests in ATLAS have focused on searches for the higgs (and studies of it subsequent to its discovery) as well as searches \u00a0for exotic new particles and Supersymmetric particles. More specifically, my current and recent research has focused on: Observation of the Higgs in the gamma gamma final state Studies of vector boson fusion production of Higgs in the ZH, H -> gamma gamma Measurement of H -> ZZ Search for new heavy Z\u2019 bosons in the tau tau final state Search for Supersymmetry in the diphoton + missing Et final state Future research topics, while far from being firmly established, are likely to include studies of H -> tau, tau\u00a0 and searches for Supersymmetry and other Exotic particles. I continue to be very involved in the operation of the TRT detector and am involved in upgrades of both the liquid argon calorimeter electronics and electronics for a new silicon tracking detector. I typically have three graduate students and a postdoctoral fellow working with me on these topics. I intend to add several graduate students in the near future. Courses Taught Fall 2010 Sabbatical to focus on ATLAS experiment at the LHC Spring 2010 Physics 151, Introduction to Electromagnetism Fall 2009 teaching relief as Principal Investigator for High Energy Physics DOE grant (10 faculty) Spring 2009 Physics 151, Introduction to Electromagnetism Fall 2008 teaching relief as Principal Investigator for High Energy Physics DOE grant (10 faculty) Spring 2008 Physics 522, Introduction to Elementary Particle Physics Fall 2007 teaching relief as Principal Investigator for High Energy Physics DOE grant (8 faculty) Spring 2007 Physics 522, Introduction to Elementary Particle Physics Fall 2006 teaching relief as Principal Investigator for High Energy Physics DOE grant (10 faculty) Search for high mass dilepton resonances in pp collisions at sqrt{s}=7 TeV with the ATLAS experiment, ATLAS Collaboration (Georges Aad et al.), Submitted to Physics Letters B, Mar 2011. 7 pp Search for high-mass states with one lepton plus missing transverse momentum in proton-proton collisions at s=7 TeV with the ATLAS detector, ATLAS Collaboration (Georges Aad et al.), submitted to Physics Letters B (8 Mar 2011) 10 pp. Search for stable hadronising squarks and gluinos with the ATLAS experiment at the LHC, ATLAS Collaboration (Georges Aad et al.), submitted to PLB (10 Mar 2011). 9 pp. Search for supersymmetry using final states with one lepton, jets, and missing transverse momentum with the ATLAS detector in sqrt{s} = 7 TeV pp, Atlas Collaboration (Georges Aad et al.), Phys. Rev. Lett. 106, 131802 (2011) 5pp. Measurement of the inclusive isolated prompt photon cross section in pp collisions at sqrt(s) = 7 TeV with the ATLAS detector, Atlas Collaboration (Georges Aad et al), Phys. Rev. D 83, 052005 (2011) 19 pp. Search for Massive Long-lived Highly Ionising Particles with the ATLAS Detector at the LHC, Atlas Collaboration (Georges Aad et al), Phys. Lett. B698 (2011) 353-370 (2 Feb 2011) Search for Diphoton Events with Large Missing Transverse Energy in 7 Main.TeV Proton-Proton Collisions with the ATLAS Detector, Atlas Collaboration (Georges Aad et al), Phys. Rev. Lett. 106, 121803 (20 Dec 2010) Measurement of the W -> lnu and Z\/gamma* -> ll production cross sections in proton-proton collisions at \u221as=7 Main.TeV with the ATLAS detector, Altas Collaboration (Georges Aad et al), JHEP 12(2010) 060 (11 Oct 2010) Studies of the performance of the ATLAS detector using cosmic-ray muons, Atlas Collaboration (Georges Aad et al), EPJC 71 (2011) 1593 (1 Dec 2010) Measurement of the W -> lnu and Z\/gamma* -> ll production cross sections in proton-proton collisions at A"
            ]
        ]
    ]
}