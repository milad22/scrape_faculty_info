{
    "columns":[
        "id",
        "google_scholar_id",
        "titles",
        "abstracts",
        "interests",
        "personal_page_content"
    ],
    "index":[
        0
    ],
    "data":[
        [
            "RS5O2WLM",
            "cluDFKcAAAAJ",
            [
                "An oscillatory hierarchy controlling neuronal excitability and stimulus processing in the auditory cortex",
                "Hippocampal structural asymmetry in unsuccessful psychopaths",
                "Neural dynamics and the fundamental mechanisms of event-related brain potentials",
                "Trial-to-trial variability of cortical evoked responses: implications for the analysis of functional connectivity",
                "A Bayesian approach to source separation",
                "Optimal data-based binning for histograms",
                "Neuropsychological correlates of hippocampal volumes in patients experiencing a first episode of schizophrenia",
                "Bayesian source separation and localization",
                "Lattice duality: The origin of probability and entropy"
            ],
            [
                "EEG oscillations are hypothesized to reflect cyclical variations in the neuronal excitability, with particular frequency bands reflecting differing spatial scales of brain operation. However, despite decades of clinical and scientific investigation, there is no unifying theory of EEG organization, and the role of ongoing activity in sensory processing remains controversial. This study analyzed laminar profiles of synaptic activity [current source density CSD] and multiunit activity (MUA), both spontaneous and stimulus-driven, in primary auditory cortex of awake macaque monkeys. Our results reveal that the EEG is hierarchically organized; delta (1\u20134 Hz) phase modulates theta (4\u201310 Hz) amplitude, and theta phase modulates gamma (30\u201350 Hz) amplitude. This oscillatory hierarchy controls baseline excitability and thus stimulus-related responses in a neuronal ensemble. We propose that the hierarchical organization of ambient \u2026",
                "Structural and functional hippocampal abnormalities have been previously reported in institutionalized psychopathic and aggressive populations. This study assessed whether prior findings of a right greater than left (R > L) functional asymmetry in caught violent offenders generalize to the structural domain in unsuccessful, caught psychopaths.Left and right hippocampal volumes were assessed using structural magnetic resonance imaging (MRI) in 23 control subjects, 16 unsuccessful psychopaths, and 12 successful (uncaught) community psychopaths and transformed into standardized space.Unsuccessful psychopaths showed an exaggerated structural hippocampal asymmetry (R > L) relative both to successful psychopaths and control subjects (p < .007) that was localized to the anterior region. This effect could not be explained by environmental and diagnostic confounds and \u2026",
                "Event-related potentials (ERPs) provide a critical link between the hemodynamic response, as measured by functional magnetic resonance imaging, and the dynamics of the underlying neuronal activity. Single-trial ERP recordings capture the oscillatory activity that are hypothesized to underlie both communication between brain regions and amplified processing of behaviorally relevant stimuli. However, precise interpretations of ERPs are precluded by uncertainty about their neural mechanisms. One influential theory holds that averaged sensory ERPs are generated by partial phase resetting of ongoing electroencephalographic oscillations, while another states that ERPs result from stimulus-evoked neural responses. We formulated critical predictions of each theory and tested these using direct, intracortical analyses of neural activity in monkeys. Our findings support a predominant role for stimulus-evoked \u2026",
                "Objectives: The time series of single trial cortical evoked potentials typically have a random appearance, and their trial-to-trial variability is commonly explained by a model in which random ongoing background noise activity is linearly combined with a stereotyped evoked response. In this paper, we demonstrate that more realistic models, incorporating amplitude and latency variability of the evoked response itself, can explain statistical properties of cortical potentials that have often been attributed to stimulus-related changes in functional connectivity or other intrinsic neural parameters.Methods: Implications of trial-to-trial evoked potential variability for variance, power spectrum, and interdependence measures like cross-correlation and spectral coherence, are first derived analytically. These implications are then illustrated using model simulations and verified experimentally by the analysis of intracortical local field \u2026",
                "The problem of source separation is by its very nature an inductive inference problem. There is not enough information to deduce the solution, so one must use any available information to infer the most probable solution. We demonstrate that source separation problems are well-suited for the Bayesian approach which provides a natural and logically consistent method by which one can incorporate prior knowledge to estimate the most probable solution given that knowledge.We derive the Bell-Sejnowski ICA algorithm from first principles, ie Bayes' Theorem and demonstrate how the Bayesian methodology makes explicit the underlying assumptions. We then further demonstrate the power of the Bayesian approach by deriving two separation algorithms that incorporate additional prior information. One algorithm separates signals that are known a priori to be decorrelated and the other utilizes information about the signal propagation through the medium from the sources to the detectors.",
                "Histograms are convenient non-parametric density estimators, which continue to be used ubiquitously. Summary quantities estimated from histogram-based probability density models depend on the choice of the number of bins. We introduce a straightforward data-based method of determining the optimal number of bins in a uniform bin-width histogram. By assigning a multinomial likelihood and a non-informative prior, we derive the posterior probability for the number of bins in a piecewise-constant density model given the data. In addition, we estimate the mean and standard deviations of the resulting bin heights, examine the effects of small sample sizes and digitized data, and demonstrate the application to multi-dimensional histograms.",
                "",
                "The problem of mixed signals occurs in many different contexts; one of the most familiar being acoustics. The forward problem in acoustics consists of finding the sound pressure levels at various detectors resulting from sound signals emanating from the active acoustic sources. The inverse problem consists of using the sound recorded by the detectors to separate the signals and recover the original source waveforms. In general, the inverse problem is unsolvable without additional information. This general problem is called source separation, and several techniques have been developed that utilize maximum entropy, minimum mutual information, and maximum likelihood. In previous work it has been demonstrated that these techniques can be recast in a Bayesian framework. This paper demonstrates the power of the Bayesian approach, which provides a natural means for incorporating prior information into a \u2026",
                "Bayesian probability theory is an inference calculus, which originates from a generalization of inclusion on the Boolean lattice of logical assertions to a degree of inclusion represented by a real number. Dual to this lattice is the distributive lattice of questions constructed from the ordered set of down-sets of assertions, which forms the foundation of the calculus of inquiry\u2014a generalization of information theory. In this paper we introduce this novel perspective on these spaces in which machine learning is performed and discuss the relationship between these results and several proposed generalizations of information theory in the literature."
            ],
            [
                [
                    "Information Physics",
                    "Probability Theory",
                    "Information Theory",
                    "Quantum Foundations",
                    "Foundations of Physics"
                ]
            ],
            [
                "Kevin Knuth Kevin Knuth Physics 309 518-442-4653 Complex Systems Summer School, Santa Fe Institute (1996) PhD\u00a0Physics, (Minor Mathematics) University of Minnesota (1995) MS\u00a0Physics, Montana State University (1990) BS\u00a0Physics and Mathematics, University of Wisconsin \u2013 Oshkosh (1988) Academic Appointments: Associate Professor, Departments of Physics and Informatics, University at Albany, Albany NY (2009-Present) Assistant Professor, Departments of Physics and Informatics, University at Albany, Albany NY (2005-2009) Research Scientist GS-14, Intelligent Systems Division, NASA Ames Research Center, Moffett Field CA. (2001-2005) Research Scientist III, Center for Advanced Brain Imaging, Nathan Kline Institute for Psychiatric Research, Orangeburg NY (1999-2001) Instructor, Department of Physiology and Biophysics, Cornell University Medical Center, New York NY (1999-2000) Instructor, Departments of Otolaryngology and Neuroscience, Albert Einstein College of Medicine, Bronx NY (1998-1999) Adjunct Assistant Professor, Speech and Hearing Sciences, Graduate School of the City University of New York, New York NY (1997-1998). Information Physics Foundations of Inference, Quantum Mechanics and Physics Inquiry, Relevance and Maximum Entropy High-Quality Bayesian Data Analysis Applications: Astrophysics Exoplanet Studies Characterization of Interstellar Organic Molecules Bayesian Source Separation Cyberphysics and Robotics Appointments: Member of the Board of Directors of the Dudley Observatory (2014 \u2013 Present) Editor-in-Chief of Entropy (MDPI) (2012 \u2013 Present) Editorial Board of Entropy (MDPI) (2010 \u2013 Present) Editorial Board of Axioms (MDPI) (2011 \u2013 Present) Sub-Committee Member of Journal on Advances in Signal Processing (JASP) Best Paper Award (2008 \u2013 Present) President and Co-Founder of Autonomous Exploration, Inc., which is a for-profit corporation focused on developing robotic autonomy (2008 \u2013 Present) Advisory Committee for the International Workshop on Bayesian Inference and Maximum Entropy Methods in Science and Engineering (MaxEnt) (1999 \u2013 Present) Honors and Awards: Third Place in the Foundational Questions Institute (FQXi 2013) Essay Contest Invited to Foundational Questions Institute (FQXi) Membership (2013) Elected Senior Member of IEEE (2008) Selected Publications: Knuth K.H., *Bahreyni N. 2014. A potential foundation for emergent space-time, Journal of Mathematical Physics, 55, 112501. http:\/\/dx.doi.org\/10.1063\/1.4899081 , arXiv:1209.0881 [math-ph] *Placek B., Knuth K.H., Angerhausen D. 2014. EXONEST: Bayesian model selection applied to the detection and characterization of exoplanets via photometric variations, Astrophysical Journal , 795(2): 112. doi:10.1088\/0004-637X\/795\/2\/112 , arXiv:1310.6764 [astro-ph.EP] Knuth K.H. 2014. Information-based physics: an observer-centric foundation. Contemporary Physics , 55(1), 12-32, (Invited Submission). doi:10.1080\/00107514.2013.853426. arXiv:1310.1667 [quant-ph] Knuth K.H. 2014. The problem of motion: the statistical mechanics of Zitterbewegung. Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Amboise, France, Sept 2014 , AIP Conference Proceedings, American Institute of Physics, Melville NY. arXiv:1411.1854 [quant-ph] *Walsh J., Knuth K.H. 2014. Information-Based Physics, Influence and Forces. Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Amboise, France, Sept 2014 , AIP Conference Proceedings, American Institute of Physics, Melville NY. arXiv:1411.2163 [quant-ph] *Placek B., Knuth K.H. 2014. A Bayesian analysis of HAT-P-7b using the EXONEST algorithm. A. Mohammad-Djafari, F. Barbaresco (eds.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Amboise, France, Sept 2014 , AIP Conference Proceedings, American Institute of Physics, Melville NY. arXiv:1409.4152 [astro-ph.EP] *Malakar N.K., *Gladkov D., and Knuth K.H. 2013. Modeling a sensor to improve its efficacy, Journal of Sensors , vol. 2013, Article ID 481054, 11 pages, 2013. doi: 10.1155\/2013\/481054 , arXiv:1303.4385 [physics.ins-det] Knuth K.H., Skilling J. 2012. Foundations of Inference. Axioms 1:38-73. (doi: 10.3390\/axioms1010038 ) Knuth K.H., *Placek B., *Richards Z. 2012. Detection and characterization of non-transiting extra-solar planets in Kepler data using reflected light variations. N. Chawla and A.N. Srivastava (eds.) Proceedings of the Conference on Intelligent Data Understanding 2012 , IEEE Explore, 31 - 38. (Digital Object Identifier: 10.1109\/CIDU.2012.6382198 ) Knuth K.H. 2012. Inferences about interactions: Fermions and the Dirac equation. U. von Toussaint (ed.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Garching, Germany, July 2012 , AIP Conference Proceedings 1553, American Institute of Physics, Melville NY. arXiv:1212.2332 [quant-ph] *Placek B., *Richards Z., Knuth K.H. 2012. Detecting non-transiting exoplanets. U. von Toussaint (ed.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Garching, Germany, July 2012 , AIP Conference Proceedings 1553, American Institute of Physics, Melville NY, 23-29. Goyal P., Knuth K.H. 2011. Quantum theory and probability theory: their relationship and origin in symmetry, Symmetry 3(2):171-206. doi: 10.3390\/sym3020171 *Malakar N.K., Knuth K.H., Lary D.J. 2011. Maximum joint entropy and information-based collaboration of automated learning machines. P. Goyal and K. H. Knuth (eds.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Waterloo, Canada, July 2011 , AIP Conference Proceedings, American Institute of Physics, Melville NY. arXiv:1111.3421 [stat.ML] *Maunu H.A., Knuth K.H. 2011. Maximum entropy production in Daisyworld. P. Goyal and K. H. Knuth (eds.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Waterloo, Canada, July 2011 , AIP Conference Proceedings, American Institute of Physics, Melville NY. Goyal P., Knuth K.H., Skilling J. 2010. Why quantum theory is complex, Physical Review A 81, 022109. arXiv:0907.0909v3 [quant-ph] Knuth K.H. 2010. Information physics: The new frontier. P. Bessiere, J.-F. Bercher, A. Mohammad-Djafari (eds.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Chamonix, France, 2010 , AIP Conference Proceedings 1305, American Institute of Physics, Melville NY, 3-19. arXiv:1009.5161v1 [math-ph] Knuth K.H., Shah A.S., Truccolo W.A., Bressler S.L., Ding M, Schroeder C.E. 2006. Differentially variable component analysis (dVCA): Identifying multiple evoked components using trial-to-trial variability. Journal of Neurophysiology , 95: 3257-3276. doi: 10.1152\/jn.00663.2005 Wheeler K.R., *Chang M.H., and Knuth K.H. 2006. Gesture based control and EMG decomposition. IEEE Transactions on Systems, Man, and Cybernetics , Part C , 36(4):503-514. doi: 10.1109\/TSMCC.2006.875418 Knuth K.H. 2005. Lattice duality: The origin of probability and entropy. Neurocomputing . 67C: 245-274. doi: 10.1016\/j.neucom.2004.11.039 Knuth K.H. 2003. Intelligent machines in the 21 st century: Automating the processes of inference and inquiry. Philosophical Transactions of the Royal Society of London A , Triennial Issue. 361(1813):2859-73. doi: 10.1098\/rsta.2003.1268 * Indicates a student under my advisement"
            ]
        ]
    ]
}