{
    "columns":[
        "id",
        "google_scholar_id",
        "titles",
        "abstracts",
        "interests",
        "personal_page_content"
    ],
    "index":[
        0
    ],
    "data":[
        [
            "L0Y48DG9",
            "T5tm9eQAAAAJ",
            [
                "Inductive Representation Learning on Large Graphs",
                "Representation Learning on Graphs: Methods and Applications",
                "Graph Convolutional Neural Networks for Web-Scale Recommender Systems",
                "Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change",
                "Hierarchical Graph Representation Learning with Differentiable Pooling",
                "GraphRNN: Generating realistic graphs with deep auto-regressive models"
            ],
            [
                "Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (eg, text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.",
                "Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (eg, degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub) graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.",
                "Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (ie, items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples \u2026",
                "Understanding how words change their meanings over time is key to models of language and cultural evolution, but historical data on meaning is scarce, making theories hard to develop and test. Word embeddings show promise as a diachronic tool, but have not been carefully evaluated. We develop a robust methodology for quantifying semantic change by evaluating word embeddings (PPMI, SVD, word2vec) against known historical changes. We then use this methodology to reveal statistical laws of semantic evolution. Using six historical corpora spanning four languages and two centuries, we propose two quantitative laws of semantic change:(i) the law of conformity---the rate of semantic change scales with an inverse power-law of word frequency;(ii) the law of innovation---independent of frequency, words that are more polysemous have higher rates of semantic change.",
                "Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs---a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DiffPool, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DiffPool learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DiffPool yields an average improvement of 5-10% accuracy on graph classification benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of five benchmark data sets.",
                "Modeling and generating graphs is fundamental for studying networks in biology, engineering, and social sciences. However, modeling complex distributions over graphs and then efficiently sampling from these distributions is challenging due to the non-unique, high-dimensional nature of graphs and the complex, non-local dependencies that exist between edges in a given graph. Here we propose GraphRNN, a deep autoregressive model that addresses the above challenges and approximates any distribution of graphs with minimal assumptions about their structure. GraphRNN learns to generate graphs by training on a representative set of graphs and decomposes the graph generation process into a sequence of node and edge formations, conditioned on the graph structure generated so far. In order to quantitatively evaluate the performance of GraphRNN, we introduce a benchmark suite of datasets, baselines and novel evaluation metrics based on Maximum Mean Discrepancy, which measure distances between sets of graphs. Our experiments show that GraphRNN significantly outperforms all baselines, learning to generate diverse graphs that match the structural characteristics of a target set, while also scaling to graphs 50 times larger than previous deep models."
            ],
            [
                [
                    "Machine Learning",
                    "Graph Representation Learning",
                    "Natural Language Processing"
                ]
            ],
            [
                "William Hamilton Professor Emeritus of Physics Ph.D., 1963 - Stanford University 281 Nicholson Hall, Tower Dr. hamilton@phys.lsu.edu Low Temperature and Experimental General Relativity Dr. Hamilton's research is directed toward improving the sensitivity and reliability\n                  of the Allegro resonant bar detector. He also is working toward improving the worldwide\n                  network of gravitational wave detectors as a charter member of the International Gravitational\n                  Event Collaboration (IGEC). The current active research consists of work with various\n                  techniques for optimal filtering following the path originated at LSU by Evan Mauceli\n                  and adaption of more sensitive dual squid amplifiers for a new generation of superconducting\n                  transducers. This work has involved collaborations with the Universities of Trento\n                  and Padova and with the University of Maryland. Current and Select Publications B. Abbott, et al., by LIGO Scientific Collaboration and TAMA Collaboration, \"Joint\n                     LIGO and TAMA300 search for gravitational waves from inspiralling neutron star binaries,\"\n                     Phys. Rev. D 73, 102002 (2006). e-Print: gr-qc\/05120768 B. Abbott, et al., by LIGO Scientific Collaboration, \"Search for gravitaional-wave\n                     bursts in LIGO's third science run,\" To appear in the proceedings of the 6th Edoardo\n                     Amaldi Conference on Gravitational Waves (Amaldi6), Kise Nago, Okinawa, Japan, 20-24\n                     June 2005; Class. Quant. Grav. 23, S29-S39 (2006). e-Print: gr-qc\/0511146 I.S. Heng, E. Daw, J. Giaime, W.O. Hamilton, M.P. McHugh, W.W. Johnson, \"Allegro:\n                     noise performance and the ongoing search for gravitational waves,\" Classical and Quantum Gravity 19(7) , 1889-1895 (2002). E. Mauceli, Z.K. Geng, W.O. Hamilton, W.W. Johnson, S. Merkowitz and A. Morse, \"The\n                     Allegro gravitational wave detector: Data acquisition and analysis,\" Phys. Rev. D 54 , 1264 (1996). N.D. Solomonson, W.O. Hamilton, W.W. Johnson, and B-X. Xu, \"Construction and performance\n                     of a low noise inductive transducer for the Louisiana State University gravitational\n                     wave detector,\" Rev. Sci. Instrum. 65 , 174-181 (1994). Z.K. Geng, P.W. Adams, W.O. Hamilton, N.D. Solomonson, \"A dc SQUID for use below 1K,\" Rev. Sci. Instrum. 64 , 1319-1323 (1993). N.D. Solomonson, W.W. Johnson, W.O. Hamilton, \"Comparative performance of two-, three-,\n                     and 4-mode gravitational radiation detectors,\" Rev. Sci. Instrum. 62 , 2299-2308 (1992). O.D. Aguiar, W.W. Johnson, W.O. Hamilton, \"A cryogenic double-resonant parabridge\n                     motion transducer for resonant-mass gravitational wave detectors,\" Rev. Sci. Instrum. 62 , 2523-2534 (1991). E. Amaldi, et al, \"First gravity wave coincidence experiment between three resonant\n                     cyrogenic detectors: Louisiana-Rome-Stanford,\" Astronomy and Astrophysics 216 , 325 (1989). G.W. Spetz, A.G. Mann, W.O. Hamilton, W.C. Oelfke, \"Experimental verification of a\n                     single transducer back-action evading measurement scheme for a gravitational wave\n                     detector,\" Physics Lett. 104A , 335 (1984)."
            ]
        ]
    ]
}