{
    "columns":[
        "id",
        "google_scholar_id",
        "titles",
        "abstracts",
        "interests",
        "personal_page_content"
    ],
    "index":[
        0
    ],
    "data":[
        [
            "WFNTX1Y5",
            "IeXW2bkAAAAJ",
            [
                "Random sampling with a reservoir",
                "The input\/output complexity of sorting and related problems",
                "External memory algorithms and data structures: dealing with massive data",
                "High-order entropy-compressed text indexes",
                "Compressed suffix arrays and suffix trees with applications to text indexing and string matching",
                "Wavelet-based histograms for selectivity estimation",
                "Design and analysis of dynamic Huffman codes",
                "Algorithms for parallel memory, I: Two-level memories",
                "Approximate computation of multidimensional aggregates of sparse data using wavelets",
                "External-memory graph algorithms"
            ],
            [
                "We introduce fast algorithms for selecting a random sample of n records without replacement from a pool of N records, where the value of N is unknown beforehand. The main result of the paper is the design and analysis of Algorithm Z; it does the sampling in one pass using constant space and in O(n(1 + log(N\/n))) expected time, which is optimum, up to a constant factor. Several optimizations are studied that collectively improve the speed of the naive version of the algorithm by an order of magnitude. We give an efficient Pascal-like implementation that incorporates these modifications and that is suitable for general use. Theoretical and empirical results indicate that Algorithm Z outperforms current methods by a significant margin.",
                "We provide tight upper and lower bounds, up to a constant factor, for the number of inputs and outputs (I\/OS) between internal memory and secondary storage required for five sorting-related problems: sorting, the fast Fourier transform (FFT), permutation networks, permuting, and matrix transposition. The bounds hold both in the worst case and in the average case, and in several situations the constant factors match. Secondary storage is modeled as a magnetic disk capable of transferring P blocks each containing B records in a single time unit; the records in each block must be input from or output to B contiguous locations on the disk. We give two optimal algorithms for the problems, which are variants of merge sorting and distribution sorting. In particular we show for P = 1 that the standard merge sorting algorithm is an optimal external sorting method, up to a constant factor in the number of I\/Os. Our sorting \u2026",
                "Data sets in large applications are often too massive to fit completely inside the computers internal memory. The resulting input\/output communication (or I\/O) between fast internal memory and slower external memory (such as disks) can be a major performance bottleneck. In this article we survey the state of the art in the design and analysis of external memory (or EM) algorithms and data structures, where the goal is to exploit locality in order to reduce the I\/O costs. We consider a variety of EM paradigms for solving batched and online problems efficiently in external memory. For the batched problem of sorting and related problems such as permuting and fast Fourier transform, the key paradigms include distribution and merging. The paradigm of disk striping offers an elegant way to use multiple disks in parallel. For sorting, however,  disk striping can be nonoptimal with respect to I\/O, so to gain further improvements \u2026",
                "We present a novel implementation of compressed su~x arrays exhibiting new tradeoffs between search time and space occupancy for a given text (or sequence) of n symbols over an alphabet E, where each symbol is encoded by lg ]E I bits. We show that compressed su1~x arrays use just nHh + O(n lglg n~ lgl~ I n) bits, while retaining full text indexing functionalities, such as searching any pattern sequence of length m in O(mlg [E[ + polylog(n)) time. The term Hh < lg IEI denotes the hth-order empirical entropy of the text, which means that our index is nearly optimal in space apart from lower-order terms, achieving asymptotically the empirical entropy of the text (with a multiplicative constant 1). If the text is highly compressible so that H~ = o(1) and the alphabet size is small, we obtain a text index with o(m) search time that requires only o(n) bits. Further results and tradeoffs are reported in the paper.",
                "The proliferation of online text, such as found on the World Wide Web and in online databases, motivates the need for space-efficient text indexing methods that support fast string searching. We model this scenario as follows: Consider a text T consisting of n symbols drawn from a fixed alphabet . The text T can be represented in  bits by encoding each symbol with  bits. The goal is to support fast online queries for searching any string pattern P of m symbols, with T being fully scanned only once, namely, when the index is created at preprocessing time. The text indexing schemes published in the literature are greedy in terms of space usage: they require  additional bits of space in the worst case. For example, in the standard unit cost RAM, suffix trees and suffix arrays need  memory words, each of  bits. These indexes are larger than the text itself by a multiplicative factor of , which is significant when  is of constant size, such as \u2026",
                "Query optimization is an integral part of relational database management systems. One important task in query optimization is selectivity estimation, that is, given a query P, we need to estimate the fraction of records in the database that satisfy P. Many commercial database systems maintain histograms to approximate the frequency distribution of values in the attributes of relations.",
                "A new one-pass algorithm for constructing dynamic Huffman codes is introduced and analyzed. We also analyze the one-pass algorithm due to Faller, Gallager, and Knuth. In each algorithm, both the sender and the receiver maintain equivalent dynamically varying Huffman trees, and the coding is done in real time. We show that the number of bits used by the new algorithm to encode a message containing t letters is < t bits more than that used by the conventional two-pass Huffman scheme, independent of the alphabet size. This is best possible in the worst case, for any one-pass Huffman method. Tight upper and lower bounds are derived. Empirical tests show that the encodings produced by the new algorithm are shorter than those of the other one-pass algorithm and, except for long messages, are shorter than those of the two-pass method. The new algorithm is well suited for on-line encoding\/decoding in data \u2026",
                "We provide the first optimal algorithms in terms of the number of input\/outputs (I\/Os) required between internal memory and multiple secondary storage devices for the problems of sorting, FFT, matrix transposition, standard matrix multiplication, and related problems. Our two-level memory model is new and gives a realistic treatmentof parallel block transfer, in which during a single I\/O each of theP secondary storage devices can simultaneously transfer a contiguous block ofB records. The model pertains to a large-scale uniprocessor system or parallel multiprocessor system withP disks. In addition, the sorting, FFT, permutation network, and standard matrix multiplication algorithms are typically optimal in terms of the amount of internal processing time. The difficulty in developing optimal algorithms is to cope with the partitioning of memory intoP separate physical devices. Our algorithms' performances can be \u2026",
                "Computing multidimensional aggregates in high dimensions is a performance bottleneck for many OLAP applications. Obtaining the exact answer to an aggregation query can be prohibitively expensive in terms of time and\/or storage space in a data warehouse environment. It is advantageous to have fast, approximate answers to OLAP aggregation queries.In this paper, we present a novel method that provides approximate answers to high-dimensional OLAP aggregation queries in massive sparse data sets in a time-efficient and space-efficient manner. We construct a compact data cube, which is an approximate and space-efficient representation of the underlying multidimensional array, based upon a multiresolution wavelet decomposition. In the on-line phase, each aggregation query can generally be answered using the compact data cube in one I\/O or a smalll number of I\/Os, depending upon the desired \u2026",
                "We present a collection of new techniques for designing and analyzing efficient external-memory algorithms for graph problems and illustrate how these techniques can be applied to a wide variety of specific problems. Our results include: Proximate-neighboring. We present a simple method for deriving external-memory lower bounds via reductions from a problem we call the \u201cproximate neighbors\u201d problem. We use this technique to derive non-trivial lower bounds for such problems as list ranking, expression tree evaluation, and connected components. PRAM simulation. We give methods for efficiently simulating PRAM computations in external memory, even for some cases in which the PRAM algorithm is not work-optimal. We apply this to derive a number of optimal (and simple) external-memory graph algorithms. Time-forward processing. We present a general technique for evaluating circuits (or \u201ccircuit-like\u201d computations) in external memory. We also usethis in a deterministic list ranking algorithm. Deterministic 3-coloring of a cycle. We give several optimal methods for 3-coloring a cycle, which can be used as a subroutine for finding large independent sets for list ranking. Our ideas go beyond a straightforward PRAM simulation, and may be of independent interest. External depth-first search. We discuss a method for performing depth first search and solving related problems efficiently in external memory. Our technique can be used in conjunction with ideas due to Ullman and Yannakakis in order to solve graph problems involving closed semi-ring computations even when their assumption that vertices fit in main memory does not hold. Our \u2026"
            ],
            [
                [
                    "Algorithms",
                    "External Memory",
                    "Compressed Data Structures",
                    "Data Compression",
                    "Parallel Computing"
                ]
            ],
            [
                "Top Jeffery Chancellor, Ph.D. Assistant Professor of Physics Ph.D., 2018 - Texas A&M 437 Nicholson Hall, Tower Dr. (office) 157 Nicholson Hall, Tower Dr. (lab) 225-578-6053 Office jchancellor1@lsu.edu Curriculum Vitae Chancellor Lab Applications of how heavy ion radiation interacts with soft and condensed matter for\n                  ground-based analogs, manned spaceflight vehicle structure, shielding, and clinical\n                  healthcare. Utilization of high-performance, multi-core computers and sophisticated\n                  numerical techniques for studying complex dynamics that are otherwise difficult to\n                  mimic in a laboratory setting. Monte Carlo modeling of heavy charged nuclei and materials\n                  and the angular discrepancy in off-axis fragments produced by inelastic nuclear interactions\n                  in particle transport code Heavy ion interactions with soft and condensed matter Radiation transport modeling (PHITS,FLUKA) Spacecraft shielding development Simulation of radiation environments in space Nuclear fission products Radiobiology Space radiation dosimetry Publications Papers Blue RS, Chancellor JC ,\u00a0Suresh R,\u00a0Carnell LS,\u00a0Reyes DP,\u00a0Nowadly CD,\u00a0Antonsen EL.\u00a0Challenges in Clinical\n                  Management of Radiation-Induced Illnesses During Exploration Spaceflight. Aerosp Med\n                  Hum Perform. 2019 Nov 1;90(11):966-977. Blue RS, Chancellor JC , Antonsen EL, Bayuse TM, Daniels, VR, Wotring, VE, Limitations in Predicting Radiation-Induced\n                  Pharmaceutical Instability during Long-Duration Spaceflight. Nature Microgravity,\n                  Jun;5(1) (2019) Chancellor JC , Guetersloh SB,Cengel KA, Ford J, Katzgraber HG, Targeted nuclear spallation from\n                  moderator block design for a ground-based space radiation analog Nature Microgravity,\n                  submitted(arXiv:1706.02727v2) (2019) Blue RS, Chancellor JC , Suresh R, Carnell L, Reyes D, Nowadly C, Antonsen EL, Challenges in managing acute\n                  space radiation-induced illnesses in exploration spaceflight Aerospace Medicine &\n                  Human Performance, submitted (2019) Chancellor JC , Blue RS, Cengel KA, Aunon SM, Rubins KH, Katzgraber HG, Kennedy AR. Limitations\n                  in predicting the space radiation health risk for exploration astronauts. Nature Microgravity,\n                  Apr;1(4) (2018) Chancellor JC , Aunon SM, Charles J. Medical Implications of Space Radiation Exposure due to low\n                  altitude polar orbits. Aerospace Medicine & Human Performance, Jan 1; 89(1):3-8 (2018) Chancellor JC , Scott GB, Sutton JP, Space Radiation: The Number One Risk to Astronaut Health beyond\n                  Low Earth Orbit. Life 4, 491 (2014), ISSN 2075-1729. Reyes DP, McClure SS, Chancellor JC , Blue RS, Castleberry TL, Vanderploeg JM. Implanted medical devices in the radiation\n                  environment of commercial spaceflight. Aerospace Medicine & Human Performance, 85(11):\n                  1106-13 (2014) Pinsky L, Chancellor JC , Status of the development of a new active personal dosimeter for use in space radiation\n                  environments. Proceedings of the IEEE Aerospace Conference Big Sky, MT, March 3\u201310.\n                  (2008) Pinsky L, Chancellor JC , Minthaka D Evolving the Medipix2 Technology For Use As An Active Space Radiation\n                  Dosimeter. IEEEAC. (2008) Pinsky L, Chancellor JC , Development of a New Active Personal Dosimeter for Use in Space Radiation Environments.\n                  IEEEAC. (2007) Book Chapters Chancellor JC , Watkins S. (2014) \u201cIonizing Radiation and Space Weather,\u201d In Mayo Clinic: Medicine\n                  in Challenging Environments for Apple iOS (Version 7.1) Stepanek J, Johnson R, Cocco\n                  D eds. Retrieved from http:\/\/www.viacuro.com\/MICE\/ Patents Space Radiation Environment Emulator U.S. Provisional Patent (2017) Radiation Detecting Wearable Devices U.S. Patent 9,759,672 B2 (2017) Jointly owned\n                     with James Ziegler, Ph.D. and Wayne Newhauser, Ph.D. Radiation Microdosimeters Correlated with Biological Cells and Cell Components U.S.\n                     Patent 8,858,888 B2 (2014) Jointly owned with James Ziegler, Ph.D. and Wayne Newhauser, Ph.D."
            ]
        ]
    ]
}